---
title             : "Validation of the Utrecht Work Engagement Scale (UWES) in the Czech Republic"
shorttitle        : "Validation of UWES"
author: 
  - name          : "Heveri Martin"
    affiliation   : "1"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Lukas Novak"
    address       : "Univerzitni 244/22, 771 11, Olomouc, Czech Republic"
    email         : "lukas.novak@oushi.upol.cz"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    role:
      - Writing - Review & Editing, 
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
      - statistical analysis
  - name          : "Iva Polackova Solcova"
    affiliation   : "1,2"
    role:
      - Writing - Review & Editing
  - name          : "Peter Tavel"
    affiliation   : "1"
    role:
      - Writing - Review & Editing
affiliation:
  - id            : "1"
    institution   : "Palacky University Olomouc - Social Health Institute"
  - id            : "2"
    institution   : "The Czech Academy of Sciences, Institute of Psychology, Prague, Czech Republic"
authornote: |
abstract: |
  Introduction
  
    One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  Sample of 707 employees (Age: M = 43.65, SD = 10.08, Females: 38.47%) recruited from different companies in the Czech Republic was used for purpouses of this study. Neuroticism, extraversion, self-efficacy, spirituality, chronic health diseases and frequency of health risk behavior were measured.
  Higher UWES total score was reported in professional workers, chief workers and in people with higher vocational school or university. The confirmatory factor analysis (CFA) supported the original three-factor solution: χ2 (24) = 75.373; p < 0.001; CFI = 0.999; TLI = 0.999; RMSEA = 0.058; SRMR = 0.021. Measrement equivalence suggested that on configural, metric, scalar and strict level, the UWES assess work engagement invariantly between males and females. The UWES had an excelent internal consistency (α = 0.96, McDonald’s ω = 0.96) and its convergent validity was supported by positive association with extraversion, self-efficacy and by negative association with neuroticism. Logistic regression revealed that higher score in the UWES was associated with lower chance of developing skin diseases and pain of unclear origin. There was no association of the UWES and health risk behaviours such as smoking, alcohol drinking or illegal drug use.
   Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
keywords          : "keywords"
wordcount         : "X"
bibliography      : ["r-references.bib"]
link-citations    : yes
linkcolor         : blue
floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_word
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
library("papaja")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(87257413)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

```{r loading libraries, include=FALSE}
packages=c("psych","dplyr","lavaan","base","foreign","Routliers","MVN","parameters", "EFA.MRFA","RGenData","semPlot","psycho","apa","corx","effectsize","qwraps2","finalfit","ggstatsplot","dunn.test","devtools","rticles","ICC.Sample.Size","tidyverse","magrittr","osfr","expss","gtsummary","huxtable","equaltestMI","haven","rcompanion","ufs","semTools","semPlot","insight","flextable","dynamic","officer","officedown") 

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages], repos = "https://cran.r-project.org/")
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
#________________________________________________________________________-
# instal MissMach currently not on the CRAN
miss.mach.url= "https://cran.r-project.org/src/contrib/Archive/MissMech/MissMech_1.0.2.tar.gz"
Miss.Pack=any(rownames(installed.packages()) == "MissMech")
if (any(Miss.Pack == FALSE)) {
  install.packages(miss.mach.url, repos=NULL, type="source")
}
library(MissMech)
#________________________________________________________________________-
# instal citr currently not on the CRAN
Miss.Pack=any(rownames(installed.packages()) == "citr")
if (any(Miss.Pack == FALSE)) {
  devtools::install_github("crsh/citr")
}
library("citr")
#________________________________________________________________________-
# install papaja currently not on the CRAN
Miss.Pack=any(rownames(installed.packages()) == "papaja")
if (any(Miss.Pack == FALSE)) {
  devtools::install_github("crsh/papaja")
}
library("papaja")
#________________________________________________________________________-
# install papaja currently not on the CRAN
Miss.Pack=any(rownames(installed.packages()) == "dynamic")
if (any(Miss.Pack == FALSE)) {
  devtools::install_local("Supplementary_materials/dynamic/")
}
library("dynamic")
#________________________________________________________________________-

# Helper functions:
# Cache Dynamic Fit Index (DFI) Cutoffs for Categorical Multi-Factor CFA Models
source("/home/rstudio/uwes-validation//R/cache_dynamic.R")
source("/home/rstudio/uwes-validation//R/create_dynamic_table.R")
```

# Introduction

Based on theoretical assumptions and previous empirical evidence [@Chan_Ho_Ip_Wong_2020] we expected significant positive association between self-efficacy and UWES total score (Hypotheses x). 

\newpage

# Methods
  
```{r data load and variable recode, include=FALSE}
path_to_dat = paste0(getwd(),"/Data")
data.raw=readRDS(paste0(path_to_dat,"/UWES_study.Rds"))
#_______________________________________________________________________
# variable recode
data.rec = data.raw %>% 
  rename("Religiosity" = "Religiosity",
         "Work_position" = "work_position") %>% 
  mutate(across(tidyr::starts_with(c("BFI_E_2","BFI_E_5","BFI_E_7")), ~dplyr::recode(., 
                                                                       "1"= 5,
                                                                       "2"= 4,
                                                                       "3"= 3,
                                                                       "4"= 2,
                                                                       "5"= 1)),
           across(tidyr::starts_with(c("BFI_N_2","BFI_N_5","BFI_N_7")), ~dplyr::recode(., 
                                                                       "1"= 5,
                                                                       "2"= 4,
                                                                       "3"= 3,
                                                                       "4"= 2,
                                                                       "5"= 1)),
         across(starts_with(c("obtize_","hlth_","UWES_","BFI_","Age")), ~ as.numeric(.)), # this can be deleted if not used    
         DSES = rowMeans(across(starts_with("DSES_"))),
         GSES = rowSums(across(starts_with("GSES_"))),
         BFI_N = rowSums(across(starts_with("BFI_N_"))),
         BFI_E = rowSums(across(starts_with("BFI_E_"))),
  # rename(hlth_for_wom_pain_in_the_small_ = hlth_women_pain_in_small_etc) %>%  # this can be deleted if not used
  UWES = rowSums(across(starts_with("UWES_"))),
  UWES_V = rowSums(across(ends_with(c("UWES_1", "UWES_2", "UWES_5")))),
  UWES_D = rowSums(across(ends_with(c("UWES_3", "UWES_4", "UWES_7")))),
  UWES_A = rowSums(across(ends_with(c("UWES_6", "UWES_8", "UWES_9"))))) %>%                    
  mutate(Education = recode_factor(Education, 
                                   "Basic school" = "Basic school", 
                                   "Vocational school or non - maturity high school" = "Non graduation high school or lower",
                                   "High school" = "High school",
                                   "Higher vocational school" = "Higher vocational school or University",
                                   "University bachelor" = "Higher vocational school or University",
                                   "University master" = "Higher vocational school or University",
                                   "University Dr" = "Higher vocational school or University",
                                   "other: Ph.D." = "Higher vocational school or University"), 
                    Economical_status = recode_factor(Economical_status, 
                                            "Student" = "Without work",
                                            "Invalidy pensioner" = "Pensioner", 
                                            "Employed" = "Working",
                                            "Enterpreanuer" = "Working",
                                            "Not working" = "Without work",
                                            "Pensioner"="Pensioner",
                                            "Maternity leave"="Without work",
                                            "Without work" = "Without work",
                                            "In household" = "Without work",
                                            "other: invalidní duchod" = "Pensioner",
                                             .default = NA_character_),
         Religiosity = recode_factor(Religiosity,
                               "Yes, I am a member or church/rel.society" = "Yes, I am a member of church",
                               "Yes, but I am not a member of church/rel.society" = "Yes, but I am not a member of a church"),
         Work_position = recode_factor(Work_position,
                                       "Worker" = "Worker",
                                       "Professional worker" = "Professional worker",
                                       "Chief worker" = "Chief worker",
                                       "High rank worker" = "Chief worker"))

# filtering only those being working
data.work = data.rec %>% 
  filter(Economical_status == "Working")

# selecting only high quality respondents
data = data.work %>% 
  filter(low_q_res == "HQ") %>% 
  mutate_if(is.factor, droplevels)


# if not used the following can be deleted
#................................................................................
# data.vacc = data.vacc %>% 
#     mutate(hlth_depression_anxiety = case_when(
#     hlth_psych_anxiety == "1" | 
#     hlth_psych_depress == "1" ~ 1, 
#     TRUE ~ 0
#   ))

# summ of all deseases
# data.vacc = data.vacc %>% 
#   mutate(General_health = rowSums(across(starts_with(c("hlth_")))))
#................................................................................

# per.male_female.pa=table(data.pa$Gender)/length(data.pa$Gender) 
per.male_female.s1=table(data$Gender)/length(data$Gender) 
```

```{r outliers screening Sample 1, inconsistent responding detection, include=FALSE}
# calculating MAD 
out_MAD.1.dat=outliers_mad(data$UWES, b = 1.4826,threshold = 2.5, na.rm = T) 
```

```{r missing data analysis, include=FALSE}
MCAR.t=MissMech::TestMCARNormality(data = select(.data = data, ends_with(c("UWES",
                                                                           "BFI_A",
                                                                           "BFI_N",
                                                                           "DSES",
                                                                           "vyska",
                                                                           "vaha"))))
```

```{r multivariate normality, include=FALSE}
# MULTIVARIATE NORMALITY 
# UWES
mvn(data = select(.data = data, starts_with("UWES_")),
    mvnTest = "mardia", univariatePlot = "histogram")

# summary: normality in UWES can be rejected  
```

```{r Homoscedasticity_and_other_assumptions, include=FALSE}
# fake regression 
random=rchisq(nrow(data), 5) # generate random data
fake_regres=lm(random~., data= data %>% select(starts_with("UWES_"))) # run fake regression
# run diagnostics plots 
plot(fake_regres) 
# testing homogenity of variances
bp.t.1 = car::ncvTest(fake_regres) # homogeneity of variances can be rejected
# bp.t.1=lmtest::bptest(fake_regres) 
```

## Participants  
  From the survey (*n* = `r nrow(data.rec)`), we excluded participants being either without work (*n* = `r nrow(filter(data.rec, Economical_status == "Without work"))`), pensioners (*n* = `r nrow(filter(data.rec, Economical_status == "Pensioner"))`) or those who did not answer a question regarding economical status (*n* = `r sum(is.na(data.rec$Economical_status),na.rm = T)`). This resulted in `r nrow(data.work)` participants. To increase data quality, we removed subjects finishing the survey in a short period of time i.e. < 15 minutes (*n* = `r nrow(filter(data.rec, status == "SPEEDER"))`). The survey typically lasted > 30 minutes. We also excluded respondents answering discrepantly to quality check items (*n* = `r nrow(data.work)-nrow(data)-nrow(filter(data.rec, status == "SPEEDER"))`). These items included information about weight, height and age. Tolerance in these control questions was set on 2 kilograms, 2 centimeters, and 2 years respectively. After removal of these subjects, the final number of participants was `r nrow(data)` (Age: *M* = `r mean(data$Age, na.rm = T) %>% round(digits = 2)`, *SD* = `r sd(data$Age, na.rm = T) %>% round(digits = 2)`, Females: `r round(per.male_female.s1[["Female"]]*100,digits = 2)`%).   

## Measures

### Utrecht Work Engagement Scale (UWES)

```{r DSES rel, include=FALSE}
# DSES  
DSES.rel=ufs::scaleStructure(select(starts_with(c("DSES_")), .data = data), digits = 2, poly = TRUE, samples = 5000)
```

### Daily Spiritual Experience Scale (DSES)

  Internal consistency of the DSES was excellent: Cronbach's $\alpha$ = `r round(DSES.rel$intermediate$alpha.ordinal.ci$est,digits=2)` 95% CI[`r round(DSES.rel$intermediate$alpha.ordinal.ci$ci.lower,digits=2)` - `r round(DSES.rel$intermediate$alpha.ordinal.ci$ci.upper,digits=2)`] and McDonald's $\omega_t$ = `r round(DSES.rel$intermediate$omega.ordinal$est, digits=2 )` 95% CI[`r round(DSES.rel$intermediate[["omega.ordinal.ci"]]$ci.lower, digits = 2)` - `r round(DSES.rel$intermediate[["omega.ordinal.ci"]]$ci.upper, digits = 2)`].

```{r GSES rel, include=FALSE}
# GSES  
GSES.rel=ufs::scaleStructure(select(starts_with(c("GSES_")), .data = data), digits = 2, poly = TRUE, samples = 5000)
```

### General Self Efficacy Scale (GSES)

  Internal consistency of the GSES was excellent: Cronbach's $\alpha$ = `r round(GSES.rel$intermediate$alpha.ordinal.ci$est,digits=2)` 95% CI[`r round(GSES.rel$intermediate$alpha.ordinal.ci$ci.lower,digits=2)` - `r round(GSES.rel$intermediate$alpha.ordinal.ci$ci.upper,digits=2)`] and McDonald's $\omega_t$ = `r round(GSES.rel$intermediate$omega.ordinal$est, digits=2 )` 95% CI[`r round(GSES.rel$intermediate[["omega.ordinal.ci"]]$ci.lower, digits = 2)` - `r round(GSES.rel$intermediate[["omega.ordinal.ci"]]$ci.upper, digits = 2)`]. 

```{r BFI_N rel, include=FALSE}
# BFI_N  
BFI_N.rel=ufs::scaleStructure(select(starts_with(c("BFI_N_")), .data = data), digits = 2, poly = TRUE, samples = 5000)
```

### Big Five Inventory - Neuroticism subscale (BFI_N)

  Internal consistency of the BFI_N was good: Cronbach's $\alpha$ = `r round(BFI_N.rel$intermediate$alpha.ordinal.ci$est,digits=2)` 95% CI[`r round(BFI_N.rel$intermediate$alpha.ordinal.ci$ci.lower,digits=2)` - `r round(BFI_N.rel$intermediate$alpha.ordinal.ci$ci.upper,digits=2)`] and McDonald's $\omega_t$ = `r round(BFI_N.rel$intermediate$omega.ordinal$est, digits=2 )` 95% CI[`r round(BFI_N.rel$intermediate[["omega.ordinal.ci"]]$ci.lower, digits = 2)` - `r round(BFI_N.rel$intermediate[["omega.ordinal.ci"]]$ci.upper, digits = 2)`]. 

```{r BFI_E rel, include=FALSE}
# BFI_E  
BFI_E.rel=ufs::scaleStructure(select(starts_with(c("BFI_E_")), .data = data), digits = 2, poly = TRUE, samples = 5000)
```
### Big Five Inventory - Extraversion subscale (BFI_E)

  Internal consistency of the BFI_E was good: Cronbach's $\alpha$ = `r round(BFI_E.rel$intermediate$alpha.ordinal.ci$est,digits=2)` 95% CI[`r round(BFI_E.rel$intermediate$alpha.ordinal.ci$ci.lower,digits=2)` - `r round(BFI_E.rel$intermediate$alpha.ordinal.ci$ci.upper,digits=2)`] and McDonald's $\omega_t$ = `r round(BFI_E.rel$intermediate$omega.ordinal$est, digits=2 )` 95% CI[`r round(BFI_E.rel$intermediate[["omega.ordinal.ci"]]$ci.lower, digits = 2)` - `r round(BFI_E.rel$intermediate[["omega.ordinal.ci"]]$ci.upper, digits = 2)`]. 

## Data analysis
  Inspection of histograms and results of the Mardia test of multivariate skewness and kurtosis indicated that the normality assumption is violated in the UWES items. Moreover, examination of residual plots and result of the Breusch-Pagan test ($\chi^2$ = `r round(bp.t.1$ChiSquare,digits=2)`, *df* = `r bp.t.1$Df`, `r format_p(bp.t.1$p)`) suggested heteroscedasticity. Thus, methods not requiring parametric assumptions were used. The Little MCAR test provided an evidence that missing values are missing on random. Thus, as there was not a large number of missing values (*n* = `r nrow(filter(data, is.na(UWES_9)))`), incomplete cases were deleted listwise.
  
  
  The instrument's factor structure was investigated via Confirmatory Factor Analysis (CFA) to test a comprehensive range of models from the literature. We first tested the original correlated three-factor model (Vigor, Dedication, Absorption) and a competing one-factor model (Schaufeli, Bakker, & Salanova, 2006). However, as many studies report strong intercorrelations among the three dimensions, suggesting they may represent a single higher-order construct (Fong & Ng, 2012), we also specified and tested a hierarchical (second-order) model (Domínguez-Salas et al., 2022). Further analyses included tests of alternative two-factor solutions (e.g., Chaudhary, Rangnekar, & Barua, 2012), a partial bi-factor model (de Bruin & Henn, 2013), and several modified three-factor models incorporating correlated error terms (e.g., Simbula et al., 2013). The Kaiser-Meyer-Olkin (KMO) measure and Bartlett’s test of sphericity were first applied to confirm the data’s suitability for factor analysis.
  Kaiser Meyer Olkin (KMO) measure together with Bartlett test of sphericity were applied to assess factorability of the UWES data. Five indices were used to inspect model fit: 1) Mean Square Error of Approximation (RMSEA); 2) Standardized Root Mean Square Residual (SRMR); 3) chi-square test; 4) Comparative Fit index (CFI) and 5) Tucker-Lewis index (TLI). In the first two indices, values below 0.08 reflects an acceptable fit and below 0.05 a good fit [@civelek2018essentials; @hoe_issues_2008; @vandenberg_review_2000; @hooper_structural_2008]. In the last two indices, values above 0.95 suggest an acceptable fit [@jackson_reporting_2009] and above 0.97 a good fit [@schermelleh_engel_evaluating_2003]. Diagonally Weighted Least Squares estimator (DWLS) on polychoric correlation matrix was used to fit CFA models.  
  
  The scale reliability was measured by the McDonald’s $\omega$ and also by the Cronbach’s $\alpha$. Convergent validity was inspected by zero order Spearman rank correlations with self-efficacy, neuroticism and with extroversion. Divergent validity was measured by correlation of the UWES with spirituality.
  
  Due to the non-normal distribution of the data, an association between the chronic health illnesses, health risk behaviour and UWES was calculated using logistic regression. In the logistic models, outcome variable was presence of an individual chronic illness or practise of health risk behaviour. The UWES score was set as a predictor. Education and work position were covariates. Both crude and adjusted effect were estimated. The p-values were corrected by Bonferroni correction.         
  
  Comparison between socio-demographic groups in the UWES total and subscale score, was performed by Mann–Whitney U test and by Kruskal–Wallis test. For post-hoc testing, Games-Howell and Dunn test were utilized. In these two tests, effect size was reported in Vargha and Delaney $\hat{A}$ [@vargha_critique_2000]. The interpretation of the $\hat{A}$ is as follows: small effect (0.56 - 0.64), medium effect (0.64 - 0.71), large effect (> 0.71). All statistical calculations were conducted in `r cite_r()`. Primary packages used for analysis included: *lavaan* [@R-lavaan], *papaja* [@R-papaja] *psych* [@R-psych], *usf* [@R-ufs].     
  
# Results

## Socio-demographic results

Results of the Kruskal-Wallis test followed by the Games-Howell and the Dunn test revealed that there are significant differences in socio-demographic groups in the UWES total and subscale scores: professional workers had significantly higher score in the UWES total and Vigor, Absorption and Dedication subscales scores as compared with workers. Similarly, chief workers reported higher UWES total score and also Dedication and Vigor subscale scores compared with workers (see Table 1). In terms of education, people with higher vocational school or university had significantly higher total and Absorption subscale score as compared with people with non graduation high school or lower education (Table 1). There were not other significant differences between socio-demographic groups. For means and standard deviations of the UWES total and subscale score see online Supplementary table 1.

```{r socio-demographic-comparison, include=FALSE}
# UWES
# Gender
car::leveneTest(as.numeric(data$UWES) ~ data$Gender, data = data, center = mean) 
# Education
car::leveneTest(as.numeric(data$UWES) ~ data$Education, data = data, center = mean) # heteroscedasticity
# Religiosity
car::leveneTest(as.numeric(data$UWES) ~ data$Religiosity, data = data, center = mean) 
# Family status
car::leveneTest(as.numeric(data$UWES) ~ data$Family_status, data = data, center = mean) 
# Work_position
car::leveneTest(as.numeric(data$UWES) ~ data$Work_position, data = data, center = mean) # heteroscedasticity
#....................................................................................................................
# UWES
# Gender
car::leveneTest(as.numeric(data$UWES_D) ~ data$Gender, data = data, center = mean) # heteroscedasticity
# Education
car::leveneTest(as.numeric(data$UWES_D) ~ data$Education, data = data, center = mean)
# Religiosity
car::leveneTest(as.numeric(data$UWES_D) ~ data$Religiosity, data = data, center = mean) 
# Family status
car::leveneTest(as.numeric(data$UWES_D) ~ data$Family_status, data = data, center = mean) 
# Work_position
car::leveneTest(as.numeric(data$UWES_D) ~ data$Work_position, data = data, center = mean) # heteroscedasticity
#....................................................................................................................
# UWES
# Gender
car::leveneTest(as.numeric(data$UWES_A) ~ data$Gender, data = data, center = mean) # heteroscedasticity
# Education
car::leveneTest(as.numeric(data$UWES_A) ~ data$Education, data = data, center = mean) # heteroscedasticity
# Religiosity
car::leveneTest(as.numeric(data$UWES_A) ~ data$Religiosity, data = data, center = mean) 
# Family status
car::leveneTest(as.numeric(data$UWES_A) ~ data$Family_status, data = data, center = mean) 
# Work_position
car::leveneTest(as.numeric(data$UWES_A) ~ data$Work_position, data = data, center = mean) # heteroscedasticity
#....................................................................................................................
# UWES
# Gender
car::leveneTest(as.numeric(data$UWES_V) ~ data$Gender, data = data, center = mean) 
# Education
car::leveneTest(as.numeric(data$UWES_V) ~ data$Education, data = data, center = mean) # heteroscedasticity
# Religiosity
car::leveneTest(as.numeric(data$UWES_V) ~ data$Religiosity, data = data, center = mean) 
# Family status
car::leveneTest(as.numeric(data$UWES_V) ~ data$Family_status, data = data, center = mean) 
# Work_position
car::leveneTest(as.numeric(data$UWES_V) ~ data$Work_position, data = data, center = mean) # heteroscedasticity


# differences between genders
# total score
wilcox.test(UWES ~ Gender, data = data)

# Vigor subscale
wilcox.test(UWES_V ~ Gender, data = data)

# Dedication subscale
wilcox.test(UWES_D ~ Gender, data = data)
t.test(UWES_D ~ Gender, data = data) # Welsh t-test


# Absorption subscale
wilcox.test(UWES_A ~ Gender, data = data)
t.test(UWES_A ~ Gender, data = data) # Welsh t-test
```

```{r table one - first part from_UWES_total_score, include=FALSE}
desc.table = data %>%
    pivot_longer(c("Gender","Education", "Family_status", "Religiosity","Work_position"),
                 names_to = "key", values_to = "value") %>%
    group_by(key,value) %>%
    summarise (mean = round(mean(UWES, na.rm = T),digits = 2),
               sd = round(sd(UWES, na.rm = T),digits = 2),
               n = n()) %>%
  mutate(percent = n / sum(n)*100)


data.to.exper = data %>%
    pivot_longer(c("Gender","Education","Family_status","Religiosity","Work_position"),
                 names_to = "key", values_to = "value") %>%
    group_by(key,value) %>%
    summarise (mean = round(mean(UWES, na.rm = T),digits = 2),
               sd = round(sd(UWES, na.rm = T),digits = 2),
               UWES = UWES,
               n = n()) %>% 
  mutate(percent = n / sum(n)*100) 

#..............................................................................................
# By the command below, there is need to explore, where are significnat differences between socio-demographic groups
#..............................................................................................
 stat.tab.1=
     data.to.exper %>%
     group_by(key) %>% 
     do(., kruskal.test(.$UWES~.$value) %>% tidy) %>% 
     mutate(UWES = "UWES") %>%
     mutate(firstrowforvar=T) %>% 
     select(key, UWES, statistic, parameter, p.value, firstrowforvar) 

 table1.categorical.both <- desc.table %>%
   group_by(key) %>%
   # we join on firstrowforvar to make sure we don't duplicate the tests
   mutate(firstrowforvar=row_number()==1) %>%
   left_join(., stat.tab.1, by=c("key", "firstrowforvar")) %>%
   # this is gross, but we don't want to repeat the variable names in our table
   ungroup() %>%
   mutate(Variables = ifelse(firstrowforvar==T, as.character(key), NA)) %>%
   select(Variables, value, n, percent,mean,sd, statistic, parameter, p.value)
#..............................................................................................
# there are significat differences in: Education, Family status and work_position 
#..............................................................................................
# removing results of Kruscal-Wallis test
table1.categorical.both = table1.categorical.both %>% 
  select(Variables,value,n, percent,mean,sd) %>% 
  mutate(mean = str_replace(mean, "NaN", NA_character_)) %>% 
  janitor::remove_empty(which = c("rows")) %>% 
  filter(!is.na(value) & !is.na(mean)) # removing missing values
#.............................................................................
#.............................................................................
# post hoc testing
#.............................................................................
#.............................................................................
# Games-Howell for Education 
oa.edu=rstatix::games_howell_test(UWES ~ Education, data = data, detailed = T) 
# Dunn test 
dunn.test(data$UWES, data$Education, list = T, altp = T, method = "bonferroni", kw=T, label = T, table = T)
# selecting significnat results from Games-Howell
edu.join=oa.edu %>% filter(p.adj < 0.05) %>%
  select(group1,group2,df,statistic,p.adj) %>%
  rename(value=group1)
#  Merging into table 1  
table.continuous =
  full_join(table1.categorical.both, edu.join)
# merging ES into table 1 
# extracting significant comparistons from the Post-hoc test
edu.es.g=oa.edu %>%
  filter(p.adj < 0.05) %>% 
  select(group1,group2)
# extracting ES from VDA
ES.edu=multiVDA(x = data$UWES, g = data$Education, statistic = "VDA", digits = 2) %>%
  as.data.frame() %>%
  separate(col = pairs.Comparison, sep = " - ", into = c("group1","group2")) %>% 
  filter(group1 == edu.es.g$group1 & group2 == edu.es.g$group2) %>%  
  select(group1,group2,pairs.VDA) %>% 
  rename(value = group1)
#  Merging into table 1  
table.continuous =
  full_join(table.continuous, ES.edu)
#................................................
# Family status 
#................................................
# Games-Howell for Family status 
uwes.fs=rstatix::games_howell_test(UWES ~ Family_status, data = data, detailed = T) 
# Dunn test 
# du=FSA::dunnTest(UWES~ Family_status,data = data, method="bonferroni")
# du=du$res %>% as_tibble()
# after post hoc testing, the resutls were not significant
#................................................
# Work_position
#................................................
# Dunn test 
dunn.test(data$UWES, data$Work_position, list = T, altp = T, method = "bonferroni", kw=T, label = T, table = T)
# Games-Howell for Work_position 
uwes.wp=rstatix::games_howell_test(UWES ~ Work_position, data = data, detailed = T) 
# selecting significnat results from Games-Howell
uwes.join=uwes.wp %>% filter(p.adj < 0.05) %>%
  select(group1,group2,df,statistic,p.adj) %>%
  rename(value=group1)
#  Merging into table 1  
table.continuous.2 =
  full_join(table1.categorical.both, uwes.join)
# merging ES into table 1 
# extracting significant comparistons from the Post-hoc test
wp.es.g=uwes.wp %>%
  filter(p.adj < 0.05) %>% 
  select(group1,group2)
# extracting ES from VDA
ES.wp=multiVDA(x = data$UWES, g = data$Work_position, statistic = "VDA", digits = 2) %>%
  as.data.frame() %>%
  separate(col = pairs.Comparison, sep = " - ", into = c("group1","group2")) %>% 
  filter(group1 == wp.es.g$group1 & group2 == wp.es.g$group2) %>%  
  select(group1,group2,pairs.VDA) %>% 
  rename(value = group1)
#  Merging into table 1  
table.continuous.2 =
  full_join(table.continuous.2, ES.wp)

# removing empty rows and NaNs 
two.var.tab=full_join(table.continuous, table.continuous.2) %>%
    mutate(mean = str_replace(mean, "NaN", NA_character_)) %>% 
  janitor::remove_empty(which = c("rows"))

# removing duplicites
two.var.tab = two.var.tab %>%
  group_by(Variables, value) %>% 
  mutate(duplicate = n()) %>% # count number of duplicite cases
  mutate(to.rm = ifelse(duplicate > 1 & is.na(group2),TRUE,FALSE)) %>%  
  filter(to.rm == FALSE) %>% 
  ungroup() %>% 
  select(!c("to.rm","duplicate"))

# sorting working status - extracting positions from original data frame
  sort.bypos = data$Work_position %>% levels()  # selecting order based on which we want to sort variable
  
# arranging
  two.var.tab = two.var.tab %>% 
  arrange(factor(value, levels = sort.bypos)) %>%  
# removing duplicate variable names
  mutate(to.rm2 = ifelse(duplicated(Variables) & !is.na(Variables),TRUE,FALSE)) %>% 
  mutate(Variables = ifelse(to.rm2 == TRUE,NA_character_, Variables)) %>% 
  select(!c("to.rm2"))
#................................
# formatting table
#...............................
two.var.tab = two.var.tab %>% 
  mutate("UWES_T: M(SD)" = paste0("",mean," (",sd,")"),
         "n(%)" = paste0("",n," ","(",round(percent,digits = 0),"%)"),
         Gr.dif.UWES.total = paste0("",group2,": ","x2(",round(df,digits = 0),")","=",round(statistic,digits = 2),
                                    "", format_p(p.adj,stars_only = T),", A=",pairs.VDA), # there are stars only to save space
         Gr.dif.UWES.total = str_replace(Gr.dif.UWES.total, pattern = "(?<=^NA:)( .*)", replacement = ""),
         Gr.dif.UWES.total = str_replace(Gr.dif.UWES.total, pattern = "^NA:", replacement = "")) %>% 
  select(Variables,value,"n(%)","UWES_T: M(SD)",Gr.dif.UWES.total) 
```

```{r table one - second part from UWES Dedication subscale score, include=FALSE}
desc.table.ded = data %>%
    pivot_longer(c("Gender","Education", "Family_status", "Religiosity","Work_position"),
                 names_to = "key", values_to = "value") %>%
    group_by(key,value) %>%
    summarise (mean = round(mean(UWES_D, na.rm = T),digits = 2),
               sd = round(sd(UWES_D, na.rm = T),digits = 2),
               n = n()) %>%
  mutate(percent = n / sum(n)*100)


data.to.exper.ded = data %>%
    pivot_longer(c("Gender","Education","Family_status","Religiosity","Work_position"),
                 names_to = "key", values_to = "value") %>%
    group_by(key,value) %>%
    summarise (mean = round(mean(UWES_D, na.rm = T),digits = 2),
               sd = round(sd(UWES_D, na.rm = T),digits = 2),
               UWES_D = as.numeric(UWES_D),
               n = n()) %>% 
  mutate(percent = n / sum(n)*100) 

#..............................................................................................
# By the command below, there is need to explore, where are significnat differences between socio-demographic groups
#..............................................................................................
 stat.tab.ded=
     data.to.exper.ded %>%
     group_by(key) %>% 
     do(., kruskal.test(.$UWES_D~.$value) %>% tidy) %>% 
     mutate(UWES_D = "UWES_D") %>%
     mutate(firstrowforvar=T) %>% 
     select(key, UWES_D, statistic, parameter, p.value, firstrowforvar) 

 table1.categorical.both.ded <- desc.table.ded %>%
   group_by(key) %>%
   # we join on firstrowforvar to make sure we don't duplicate the tests
   mutate(firstrowforvar=row_number()==1) %>%
   left_join(., stat.tab.ded, by=c("key", "firstrowforvar")) %>%
   # this is gross, but we don't want to repeat the variable names in our table
   ungroup() %>%
   mutate(Variables = ifelse(firstrowforvar==T, as.character(key), NA)) %>%
   select(Variables, value, n, percent,mean,sd, statistic, parameter, p.value)
#..............................................................................................
# there are significat differences in: Education, Family status and work_position 
#..............................................................................................
# removing results of Kruscal-Wallis test
table1.categorical.both.ded = table1.categorical.both.ded %>% 
  select(Variables,value,n, percent,mean,sd) %>% 
  mutate(mean = str_replace(mean, "NaN", NA_character_)) %>% 
  janitor::remove_empty(which = c("rows")) %>% 
  filter(!is.na(value) & !is.na(mean)) # removing missing values
#.............................................................................
#.............................................................................
# post hoc testing
#.............................................................................
#.............................................................................
# Games-Howell for Education 
oa.edu.ded=rstatix::games_howell_test(UWES_D ~ Education, data = data, detailed = T) # all ns 
# Dunn test 
dunn.test(data$UWES_D, data$Education, list = T, altp = T, method = "bonferroni", kw=T, label = T, table = T)
# selecting significnat results from Games-Howell
edu.join.ded=oa.edu.ded %>% filter(p.adj < 0.05) %>%
  select(group1,group2,df,statistic,p.adj) %>%
  rename(value=group1)
#  Merging into table 1  
table.continuous.ded =
  full_join(table1.categorical.both.ded, edu.join.ded)
# merging ES into table 1 
# extracting significant comparistons from the Post-hoc test
edu.es.g.ded=oa.edu.ded %>%
  filter(p.adj < 0.05) %>% 
  select(group1,group2)
# ..........................this code is not run because when result is not significnat code can not be runned
# extracting ES from VDA  
# ES.edu.ded=multiVDA(x = data$UWES_D, g = data$Education, statistic = "VDA", digits = 2) %>% 
#   as.data.frame() %>%
#   separate(col = pairs.Comparison, sep = " - ", into = c("group1","group2")) %>% 
#   filter(group1 == edu.es.g.ded$group1 & group2 == edu.es.g.ded$group2) %>%  
#   select(group1,group2,pairs.VDA) %>% 
#   rename(value = group1)
#  Merging into table 1  
# table.continuous =
#   full_join(table.continuous, ES.edu.ded)
#.........................
#................................................
# Family status 
#................................................
# Work_position
#................................................
# Dunn test 
dunn.test(data$UWES_D, data$Work_position, list = T, altp = T, method = "bonferroni", kw=T, label = T, table = T)
# Games-Howell for Work_position 
UWES_D.wp=rstatix::games_howell_test(UWES_D ~ Work_position, data = data, detailed = T) 
# selecting significnat results from Games-Howell
UWES_D.join=UWES_D.wp %>% filter(p.adj < 0.05) %>%
  select(group1,group2,df,statistic,p.adj) %>%
  rename(value=group1)
#  Merging into table 1  
table.continuous.2.ded =
  full_join(table1.categorical.both.ded, UWES_D.join)
# merging ES into table 1 
# extracting significant comparistons from the Post-hoc test
wp.es.g.ded=UWES_D.wp %>%
  filter(p.adj < 0.05) %>% 
  select(group1,group2)
# extracting ES from VDA
ES.wp.ded=multiVDA(x = data$UWES_D, g = data$Work_position, statistic = "VDA", digits = 2) %>%
  as.data.frame() %>%
  separate(col = pairs.Comparison, sep = " - ", into = c("group1","group2")) %>% 
  filter(group1 == wp.es.g.ded$group1 & group2 == wp.es.g.ded$group2) %>%  
  select(group1,group2,pairs.VDA) %>% 
  rename(value = group1)
#  Merging into table 1  
table.continuous.2.ded =
  full_join(table.continuous.2.ded, ES.wp.ded) 

# removing empty rows and NaNs 
two.var.tab.ded=full_join(table.continuous.ded, table.continuous.2.ded) %>%
    mutate(mean = as.numeric(str_replace(mean, "NaN", NA_character_))) %>% 
  janitor::remove_empty(which = c("rows"))

# removing duplicites
two.var.tab.ded = two.var.tab.ded %>%
  group_by(Variables, value) %>% 
  mutate(duplicate = n()) %>% # count number of duplicite cases
  mutate(to.rm = ifelse(duplicate > 1 & is.na(group2),TRUE,FALSE)) %>%  
  filter(to.rm == FALSE) %>% 
  ungroup() %>% 
  select(!c("to.rm","duplicate"))

# sorting working status - extracting positions from original data frame
  sort.bypos = data$Work_position %>% levels()  # selecting order based on which we want to sort variable
  
# arranging
two.var.tab.ded = two.var.tab.ded %>% 
  arrange(factor(value, levels = sort.bypos)) %>%  
  # removing duplicate variable names
  mutate(to.rm2 = ifelse(duplicated(Variables) & !is.na(Variables), TRUE, FALSE)) %>% 
  mutate(Variables = ifelse(to.rm2 == TRUE, NA_character_, Variables)) %>% 
  select(!c("to.rm2")) %>% 
  #................................
  # formatting table
  #................................
  mutate(
    `UWES_D: M(SD)` = paste0(sprintf("%.1f", `mean`), " (", sprintf("%.2f", `sd`), ")"),
    `n(%)` = paste0(n, " (", round(percent, digits = 0), "%)"),
    Gr.dif.UWES_D.total = paste0(
      group2, ": ",
      "x2(", round(`df`, digits = 0), ") = ", round(`statistic`, digits = 2),
      format_p(`p.adj`, stars_only = TRUE),
      ", A = ", `pairs.VDA`
    ),
    Gr.dif.UWES_D.total = str_replace(Gr.dif.UWES_D.total, pattern = "(?<=^NA:)( .*)", replacement = ""),
    Gr.dif.UWES_D.total = str_replace(Gr.dif.UWES_D.total, pattern = "^NA:", replacement = "")
  ) %>% 
  select(Variables, value, `n(%)`, `UWES_D: M(SD)`, Gr.dif.UWES_D.total)

```

```{r table one - third part from UWES Vigor subscale score, include=FALSE}
desc.table.vig = data %>%
    pivot_longer(c("Gender","Education", "Family_status", "Religiosity","Work_position"),
                 names_to = "key", values_to = "value") %>%
    group_by(key,value) %>%
    summarise (mean = round(mean(UWES_V, na.rm = T),digits = 2),
               sd = round(sd(UWES_V, na.rm = T),digits = 2),
               n = n()) %>%
  mutate(percent = n / sum(n)*100)


data.to.exper.vig = data %>%
    pivot_longer(c("Gender","Education","Family_status","Religiosity","Work_position"),
                 names_to = "key", values_to = "value") %>%
    group_by(key,value) %>%
    summarise (mean = round(mean(UWES_V, na.rm = T),digits = 2),
               sd = round(sd(UWES_V, na.rm = T),digits = 2),
               UWES_V = as.numeric(UWES_V),
               n = n()) %>% 
  mutate(percent = n / sum(n)*100) 

#..............................................................................................
# By the command below, there is need to explore, where are significnat differences between socio-demographic groups
#..............................................................................................
 stat.tab.vig=
     data.to.exper.vig %>%
     group_by(key) %>% 
     do(., kruskal.test(.$UWES_V~.$value) %>% tidy) %>% 
     mutate(UWES_V = "UWES_V") %>%
     mutate(firstrowforvar=T) %>% 
     select(key, UWES_V, statistic, parameter, p.value, firstrowforvar) 

 table1.categorical.both.vig <- desc.table.vig %>%
   group_by(key) %>%
   # we join on firstrowforvar to make sure we don't duplicate the tests
   mutate(firstrowforvar=row_number()==1) %>%
   left_join(., stat.tab.vig, by=c("key", "firstrowforvar")) %>%
   # this is gross, but we don't want to repeat the variable names in our table
   ungroup() %>%
   mutate(Variables = ifelse(firstrowforvar==T, as.character(key), NA)) %>%
   select(Variables, value, n, percent,mean,sd, statistic, parameter, p.value)
#..............................................................................................
# there are significat differences in: Education, Family status and work_position 
#..............................................................................................
# removing results of Kruscal-Wallis test
table1.categorical.both.vig = table1.categorical.both.vig %>% 
  select(Variables,value,n, percent,mean,sd) %>% 
  mutate(mean = str_replace(mean, "NaN", NA_character_)) %>% 
  janitor::remove_empty(which = c("rows")) %>% 
  filter(!is.na(value) & !is.na(mean)) # removing missing values
#.............................................................................
#.............................................................................
# post hoc testing
#.............................................................................
#.............................................................................
# Games-Howell for Education 
oa.edu.vig=rstatix::games_howell_test(UWES_V ~ Education, data = data, detailed = T) # all ns 
# Dunn test 
dunn.test(data$UWES_V, data$Education, list = T, altp = T, method = "bonferroni", kw=T, label = T, table = T)
# selecting significnat results from Games-Howell
edu.join.vig=oa.edu.vig %>% filter(p.adj < 0.05) %>%
  select(group1,group2,df,statistic,p.adj) %>%
  rename(value=group1)
#  Merging into table 1  
table.continuous.vig =
  full_join(table1.categorical.both.vig, edu.join.vig)
# merging ES into table 1 
# extracting significant comparistons from the Post-hoc test
edu.es.g.vig=oa.edu.vig %>%
  filter(p.adj < 0.05) %>% 
  select(group1,group2)
# ..........................this code is not run because when result is not significnat code can not be runned
# extracting ES from VDA  
# ES.edu.vig=multiVDA(x = data$UWES_V, g = data$Education, statistic = "VDA", digits = 2) %>% 
#   as.data.frame() %>%
#   separate(col = pairs.Comparison, sep = " - ", into = c("group1","group2")) %>% 
#   filter(group1 == edu.es.g.vig$group1 & group2 == edu.es.g.vig$group2) %>%  
#   select(group1,group2,pairs.VDA) %>% 
#   rename(value = group1)
#  Merging into table 1  
# table.continuous =
#   full_join(table.continuous, ES.edu.vig)
#.........................
#................................................
# Family status 
#................................................
# Work_position
#................................................
# Dunn test 
dunn.test(data$UWES_V, data$Work_position, list = T, altp = T, method = "bonferroni", kw=T, label = T, table = T)
# Games-Howell for Work_position 
UWES_V.wp=rstatix::games_howell_test(UWES_V ~ Work_position, data = data, detailed = T) 
# selecting significnat results from Games-Howell
UWES_V.join=UWES_V.wp %>% filter(p.adj < 0.05) %>%
  select(group1,group2,df,statistic,p.adj) %>%
  rename(value=group1)
#  Merging into table 1  
table.continuous.2.vig =
  full_join(table1.categorical.both.vig, UWES_V.join)
# merging ES into table 1 
# extracting significant comparistons from the Post-hoc test
wp.es.g.vig=UWES_V.wp %>%
  filter(p.adj < 0.05) %>% 
  select(group1,group2)
# extracting ES from VDA
ES.wp.vig=multiVDA(x = data$UWES_V, g = data$Work_position, statistic = "VDA", digits = 2) %>%
  as.data.frame() %>%
  separate(col = pairs.Comparison, sep = " - ", into = c("group1","group2")) %>% 
  filter(group1 == wp.es.g.vig$group1 & group2 == wp.es.g.vig$group2) %>%  
  select(group1,group2,pairs.VDA) %>% 
  rename(value = group1)
#  Merging into table 1  
table.continuous.2.vig =
  full_join(table.continuous.2.vig, ES.wp.vig) 

# removing empty rows and NaNs 
two.var.tab.vig=full_join(table.continuous.vig, table.continuous.2.vig) %>%
    mutate(mean = str_replace(mean, "NaN", NA_character_)) %>% 
  janitor::remove_empty(which = c("rows"))

# removing duplicites
two.var.tab.vig = two.var.tab.vig %>%
  group_by(Variables, value) %>% 
  mutate(duplicate = n()) %>% # count number of duplicite cases
  mutate(to.rm = ifelse(duplicate > 1 & is.na(group2),TRUE,FALSE)) %>%  
  filter(to.rm == FALSE) %>% 
  ungroup() %>% 
  select(!c("to.rm","duplicate"))

# sorting working status - extracting positions from original data frame
  sort.bypos = data$Work_position %>% levels()  # selecting order based on which we want to sort variable
  
# arranging
  two.var.tab.vig = two.var.tab.vig %>% 
  arrange(factor(value, levels = sort.bypos)) %>%  
# removing duplicate variable names
  mutate(to.rm2 = ifelse(duplicated(Variables) & !is.na(Variables),TRUE,FALSE)) %>% 
  mutate(Variables = ifelse(to.rm2 == TRUE,NA_character_, Variables)) %>% 
  select(!c("to.rm2"))
#................................
# formatting table
#...............................
two.var.tab.vig = two.var.tab.vig %>% 
  mutate("UWES_V: M(SD)" = paste0("",mean," (",sd,")"),
         "n(%)" = paste0("",n," ","(",round(percent,digits = 0),"%)"),
         Gr.dif.UWES_V.total = paste0("",group2,": ","x2(",round(df,digits = 0),")","=",round(statistic,digits = 2),
                                    "", format_p(p.adj,stars_only = T),", A=",pairs.VDA), # there are stars only to save space
         Gr.dif.UWES_V.total = str_replace(Gr.dif.UWES_V.total, pattern = "(?<=^NA:)( .*)", replacement = ""),
         Gr.dif.UWES_V.total = str_replace(Gr.dif.UWES_V.total, pattern = "^NA:", replacement = "")) %>% 
  select(Variables,value,"n(%)","UWES_V: M(SD)",Gr.dif.UWES_V.total) 
```

```{r table one - third part from UWES ABSORBTION subscale score, include=FALSE}
desc.table.abs = data %>%
    pivot_longer(c("Gender","Education", "Family_status", "Religiosity","Work_position"),
                 names_to = "key", values_to = "value") %>%
    group_by(key,value) %>%
    summarise (mean = round(mean(UWES_A, na.rm = T),digits = 2),
               sd = round(sd(UWES_A, na.rm = T),digits = 2),
               n = n()) %>%
  mutate(percent = n / sum(n)*100)


data.to.exper.abs = data %>%
    pivot_longer(c("Gender","Education","Family_status","Religiosity","Work_position"),
                 names_to = "key", values_to = "value") %>%
    group_by(key,value) %>%
    summarise (mean = round(mean(UWES_A, na.rm = T),digits = 2),
               sd = round(sd(UWES_A, na.rm = T),digits = 2),
               UWES_A = as.numeric(UWES_A),
               n = n()) %>% 
  mutate(percent = n / sum(n)*100) 

#..............................................................................................
# By the command below, there is need to explore, where are significnat differences between socio-demographic groups
#..............................................................................................
 stat.tab.abs=
     data.to.exper.abs %>%
     group_by(key) %>% 
     do(., kruskal.test(.$UWES_A~.$value) %>% tidy) %>% 
     mutate(UWES_A = "UWES_A") %>%
     mutate(firstrowforvar=T) %>% 
     select(key, UWES_A, statistic, parameter, p.value, firstrowforvar) 

 table1.categorical.both.abs <- desc.table.abs %>%
   group_by(key) %>%
   # we join on firstrowforvar to make sure we don't duplicate the tests
   mutate(firstrowforvar=row_number()==1) %>%
   left_join(., stat.tab.abs, by=c("key", "firstrowforvar")) %>%
   # this is gross, but we don't want to repeat the variable names in our table
   ungroup() %>%
   mutate(Variables = ifelse(firstrowforvar==T, as.character(key), NA)) %>%
   select(Variables, value, n, percent,mean,sd, statistic, parameter, p.value)
#..............................................................................................
# there are significat differences in: Education, Family status and work_position 
#..............................................................................................
# removing results of Kruscal-Wallis test
table1.categorical.both.abs = table1.categorical.both.abs %>% 
  select(Variables,value,n, percent,mean,sd) %>% 
  mutate(mean = str_replace(mean, "NaN", NA_character_)) %>% 
  janitor::remove_empty(which = c("rows")) %>% 
  filter(!is.na(value) & !is.na(mean)) # removing missing values
#.............................................................................
#.............................................................................
# post hoc testing
#.............................................................................
#.............................................................................
# Games-Howell for Education 
oa.edu.abs=rstatix::games_howell_test(UWES_A ~ Education, data = data, detailed = T) # all ns 
# Dunn test 
dunn.test(data$UWES_A, data$Education, list = T, altp = T, method = "bonferroni", kw=T, label = T, table = T)
# selecting significnat results from Games-Howell
edu.join.abs=oa.edu.abs %>% filter(p.adj < 0.01) %>% # THERE IS NEED TO BE EXTRA CARAFUL! - DUE TO THE DIFFERENCES BETWEEN DUNN AND GAMES HOWEL TEST, ONLY RESULTS BELO P # < 0.01 ARE SELECTED BECAUSE THIS SELECTS RESULTS WHICH WERE SIGNIFICANT IN BOTH GAMES-HOWEL AND DUNN TEST 
  select(group1,group2,df,statistic,p.adj) %>%
  rename(value=group1)
#  Merging into table 1  
table.continuous.abs =
  full_join(table1.categorical.both.abs, edu.join.abs)
# merging ES into table 1 
# extracting significant comparistons from the Post-hoc test
edu.es.g.abs=oa.edu.abs %>%
  filter(p.adj < 0.01) %>% # THERE IS NEED TO BE EXTRA CARAFUL! - DUE TO THE DIFFERENCES BETWEEN DUNN AND GAMES HOWEL TEST, ONLY 
  select(group1,group2)
# extracting ES from VDA  
ES.edu.abs=multiVDA(x = data$UWES_A, g = data$Education, statistic = "VDA", digits = 2) %>%
  as.data.frame() %>%
  separate(col = pairs.Comparison, sep = " - ", into = c("group1","group2")) %>%
  filter(group1 == edu.es.g.abs$group1 & group2 == edu.es.g.abs$group2) %>%
  select(group1,group2,pairs.VDA) %>%
  rename(value = group1)
# Merging into table 1
table.continuous.abs =
  full_join(table.continuous.abs, ES.edu.abs)
#................................................
# Family status 
#................................................
# Work_position
#................................................
# Dunn test 
dunn.test(data$UWES_A, data$Work_position, list = T, altp = T, method = "bonferroni", kw=T, label = T, table = T)
# Games-Howell for Work_position 
UWES_A.wp=rstatix::games_howell_test(UWES_A ~ Work_position, data = data, detailed = T) 
# selecting significnat results from Games-Howell
UWES_A.join=UWES_A.wp %>% filter(p.adj < 0.05) %>%
  select(group1,group2,df,statistic,p.adj) %>%
  rename(value=group1)
#  Merging into table 1  
table.continuous.2.abs =
  full_join(table1.categorical.both.abs, UWES_A.join)
# merging ES into table 1 
# extracting significant comparistons from the Post-hoc test
wp.es.g.abs=UWES_A.wp %>%
  filter(p.adj < 0.05) %>% 
  select(group1,group2)
# extracting ES from VDA
ES.wp.abs=multiVDA(x = data$UWES_A, g = data$Work_position, statistic = "VDA", digits = 2) %>%
  as.data.frame() %>%
  separate(col = pairs.Comparison, sep = " - ", into = c("group1","group2")) %>% 
  filter(group1 == wp.es.g.abs$group1 & group2 == wp.es.g.abs$group2) %>%  
  select(group1,group2,pairs.VDA) %>% 
  rename(value = group1)
#  Merging into table 1  
table.continuous.2.abs =
  full_join(table.continuous.2.abs, ES.wp.abs) 

# removing empty rows and NaNs 
two.var.tab.abs=full_join(table.continuous.abs, table.continuous.2.abs) %>%
    mutate(mean = str_replace(mean, "NaN", NA_character_)) %>% 
  janitor::remove_empty(which = c("rows"))

# removing duplicites
two.var.tab.abs = two.var.tab.abs %>%
  group_by(Variables, value) %>% 
  mutate(duplicate = n()) %>% # count number of duplicite cases
  mutate(to.rm = ifelse(duplicate > 1 & is.na(group2),TRUE,FALSE)) %>%  
  filter(to.rm == FALSE) %>% 
  ungroup() %>% 
  select(!c("to.rm","duplicate"))

# sorting working status - extracting positions from original data frame
  sort.bypos = data$Work_position %>% levels()  # selecting order based on which we want to sort variable
  
# arranging
  two.var.tab.abs = two.var.tab.abs %>% 
  arrange(factor(value, levels = sort.bypos)) %>%  
# removing duplicate variable names
  mutate(to.rm2 = ifelse(duplicated(Variables) & !is.na(Variables),TRUE,FALSE)) %>% 
  mutate(Variables = ifelse(to.rm2 == TRUE,NA_character_, Variables)) %>% 
  select(!c("to.rm2"))
#................................
# formatting table
#...............................
two.var.tab.abs = two.var.tab.abs %>% 
  mutate("UWES_A: M(SD)" = paste0("",mean," (",sd,")"),
         "n(%)" = paste0("",n," ","(",round(percent,digits = 0),"%)"),
         Gr.dif.UWES_A.total = paste0("",group2,": ","x2(",round(df,digits = 0),")","=",round(statistic,digits = 2),
                                    "", format_p(p.adj,stars_only = T),", A=",pairs.VDA), # there are stars only to save space
         Gr.dif.UWES_A.total = str_replace(Gr.dif.UWES_A.total, pattern = "(?<=^NA:)( .*)", replacement = ""),
         Gr.dif.UWES_A.total = str_replace(Gr.dif.UWES_A.total, pattern = "^NA:", replacement = "")) %>% 
  select(Variables,value,"n(%)","UWES_A: M(SD)",Gr.dif.UWES_A.total) 
```

```{r, echo=FALSE}
# merging tables togather
two.var.tab.merg = two.var.tab %>% 
  select(starts_with(c("Variables","value","n(%)","Gr.dif.")))

two.var.tab.ded.merg = two.var.tab.ded %>% 
  select(starts_with(c("Variables","value","n(%)","Gr.dif.")))

two.var.tab.abs.merg = two.var.tab.abs %>% 
  select(starts_with(c("Variables","value","n(%)","Gr.dif.")))

two.var.tab.vig.merg = two.var.tab.vig %>% 
  select(starts_with(c("Variables","value","n(%)","Gr.dif.")))

soc.dem.tb=full_join(two.var.tab.merg,
          two.var.tab.ded.merg) 
soc.dem.tb= full_join(soc.dem.tb, two.var.tab.abs.merg, by = c("Variables", "value", "n(%)"))
soc.dem.tb = full_join(soc.dem.tb, two.var.tab.vig.merg, by = c("Variables", "value", "n(%)"))

# renaming
soc.dem.tb = soc.dem.tb %>% 
  rename("UWES_T" ="Gr.dif.UWES.total",
         "UWES_D" = "Gr.dif.UWES_D.total",
         "UWES_A" = "Gr.dif.UWES_A.total",
         "UWES_V" = "Gr.dif.UWES_V.total")

soc.dem.tb %>%  
  as_tibble() %>% 
  mutate_all(~(replace(., is.na(.), ""))) %>%
  as_huxtable(add_colnames = F) %>% 
  set_bottom_border(row = 1, value = 1) %>%  # the 1 here indicates the rownumber 
  set_font("times") %>% 
  set_font_size(10) %>% 
  apa_table(caption = "Socio-demographic results of the three samples", span_text_columns = F)
```

\newpage

```{r table with means and SD of the UWES, echo=FALSE}
# merging MEANS AND SD TOGETHER
m.sd.tab=full_join(two.var.tab,
          two.var.tab.abs) 
m.sd.tab= full_join(m.sd.tab, two.var.tab.ded)
m.sd.tab = full_join(m.sd.tab, two.var.tab.vig)

# selecting means and SDs 
m.sd.tab = m.sd.tab %>% 
  select(ends_with(c("Variables","value","M(SD)")))

# removing duplicates
 m.sd.tab = m.sd.tab %>%  
  mutate(to.rm = ifelse(duplicated(`UWES_T: M(SD)`) | is.na(`UWES_T: M(SD)`) &
                        duplicated(`UWES_D: M(SD)`) | is.na(`UWES_D: M(SD)`) &
                        duplicated(`UWES_A: M(SD)`) | is.na(`UWES_A: M(SD)`) &
                        duplicated(`UWES_V: M(SD)`) | is.na(`UWES_V: M(SD)`) |
                          duplicated(value),TRUE,FALSE)) %>% 
  filter(to.rm == FALSE) %>% 
  select(!c("to.rm"))
```

```{r echo=FALSE}
# Table 
 m.sd.tab %>%   
  as_tibble() %>% 
  mutate_all(~(replace(., is.na(.), ""))) %>%
  as_huxtable(add_colnames = F) %>% 
  set_bottom_border(row = 1, value = 1) %>%  # the 1 here indicates the rownumber 
  set_font("times") %>% 
  set_font_size(10) %>% 
  apa_table(caption = "Means and standard deviations of the UWES total and subscale scores", span_text_columns = F,
            note = "SD = standard deviation, M = mean, UWES_T = Utrecht Work Engagement Scale - Total score, UWES_A = Utrecht Work Engagement Scale - Absorption subscale, UWES_D = Utrecht Work Engagement Scale - Dedication subscale, UWES_V = Utrecht Work Engagement Scale - Vigor subscale")
```

```{r Bartlett test and KMO, include=FALSE}
# POLYCHORIC CORELATION MATRIX
# UWES 
UWES.rep.poly = data %>% select(starts_with(c("UWES_1", "UWES_2", "UWES_5","UWES_3",
                                              "UWES_4", "UWES_7","UWES_6", "UWES_8", "UWES_9"))) %>% lavCor(ordered = T)
# BARTLETS TEST OF SPHERICITY:
bartlett.UWES=cortest.bartlett(UWES.rep.poly, diag = T, n=nrow(data)) #  Bartlett's test of sphericity 
# KMO
KMO(UWES.rep.poly) # 0.96
```

```{r CFA-UWES-three-fac, include=FALSE}
# three factor model 
three.fac.mod = "Vigor =~ UWES_1 + UWES_2 + UWES_5 
               Dedication =~ UWES_3 + UWES_4 + UWES_7
               Absorption =~ UWES_6 + UWES_8 + UWES_9"
# when "ordered" is set to "TRUE", than DWLS estimator is automatically used as "standard" in results. 
# "Robust" chisquare in results is referring to WLSMV estimator.
UWES.three.fac=sem(model = three.fac.mod, data = data, std.lv=T, ordered = T, estimator = "WLSMV")
three.fac.mod.sum=summary(UWES.three.fac,rsquare=T, standardized=T, fit.measures=T)
modificationindices(UWES.three.fac, sort. = T) # how can we improve our model
# inspection of correlation between residuals
# Large positive values indicate the model underpredicts the correlation; large negative values suggest overprediction of the correlation. Usually values |r>.1| are worth closer consideration.
resid(UWES.three.fac, "cor")

DFI_three_factor <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = UWES.three.fac,
  estimator = "WLSMV",
  data = data
  )

# https://groups.google.com/g/lavaan/c/DlVaoP41MyI

# https://groups.google.com/g/lavaan/c/G-eVdgqWZ24


```

```{r CFA_two_factor_model, include=FALSE}
# two factor model 
two.fac.mod="VigDeg =~ UWES_1 + UWES_2 + UWES_3 + UWES_4 + UWES_5 + UWES_7
             Abs =~  UWES_6 + UWES_8 + UWES_9"

#when "ordered" is set to "TRUE", than DWLS estimator is auto  matically used as "standard" in results. "Robust" chisquare in results is referring to WLSMV estimator.
UWES.two.fac=cfa(model = two.fac.mod, data = data, std.lv=T, ordered = T)
two.fac.mod.sum=summary(UWES.two.fac,rsquare=T, standardized=T, fit.measures=T)
parameterestimates(UWES.two.fac, standardized = T) # whill show standardized estimates and many other things
modificationindices(UWES.two.fac, sort. = T) # how can we improve our model
fitmeasures(UWES.two.fac) # chisq.scaled - robust one

# DFI
DFI_two_factor <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = UWES.two.fac,
  data = data
  )

one.fac.mod.cor.er.UWES.resid=resid(UWES.two.fac, "cor")
dif.test.two.three.fac=lavaan::anova(UWES.three.fac,UWES.two.fac)

```

```{r CFA_one_factor_model, include=FALSE}
# one factor model 
one.fac.mod="WE =~ UWES_1 + UWES_2 + UWES_3 + UWES_4 + UWES_5 + UWES_6 + UWES_7 + UWES_8 + UWES_9"

#when "ordered" is set to "TRUE", than DWLS estimator is auto  matically used as "standard" in results. "Robust" chisquare in results is referring to WLSMV estimator.
UWES.one.fac=sem(model = one.fac.mod, data = data, std.lv=T, ordered = T)
one.fac.mod.sum=summary(UWES.one.fac,rsquare=T, standardized=T, fit.measures=T)
parameterestimates(UWES.one.fac, standardized = T) # whill show standardized estimates and many other things
modificationindices(UWES.one.fac, sort. = T) # how can we improve our model
fitmeasures(UWES.one.fac) # chisq.scaled - robust one

# DFI
DFI_one_factor <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = UWES.one.fac,
  data = data
  )

one.fac.mod.cor.er.UWES.resid=resid(UWES.one.fac, "cor")
dif.test.one.three.fac=lavaan::anova(UWES.three.fac,UWES.one.fac)
```

```{r CFA_hierarchical_factor_model, include=FALSE}

# # Define the names of the ordered categorical variables
# ordered_vars <- c("UWES_1", "UWES_2", "UWES_3", "UWES_4", "UWES_5", 
#                   "UWES_6", "UWES_7", "UWES_8", "UWES_9")

# one factor model 
hier.fac.mod=" Dedication =~ UWES_3 + UWES_4 + UWES_7
               Absorption =~ UWES_6 + UWES_8 + UWES_9
               Vigor =~ UWES_1 + UWES_2 + UWES_5
               WE =~ Dedication + Absorption + Vigor"

#when "ordered" is set to "TRUE", than DWLS estimator is auto  matically used as "standard" in results. "Robust" chisquare in results is referring to WLSMV estimator.
UWES.hier.fac.hier=sem(model = hier.fac.mod, data = data, std.lv=T, ordered = T)
hier.fac.mod.sum=summary(UWES.hier.fac.hier,rsquare=T, standardized=T, fit.measures=T)
parameterestimates(UWES.hier.fac.hier, standardized = T) # whill show standardized estimates and many other things
modificationindices(UWES.hier.fac.hier, sort. = T) # how can we improve our model
fitmeasures(UWES.hier.fac.hier) # chisq.scaled - robust one

# DFI
DFI_hierarch_factor <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = UWES.hier.fac.hier,
  data = data
  )

# one.fac.mod.cor.er.UWES.resid=resid(UWES.hier.fac.hier, "cor")
# dif.test.one.three.fac=lavaan::anova(UWES.three.fac,UWES.hier.fac.hier)
```

```{r CFA_partial_bi_factor_model_de_Bruin, eval=FALSE, include=FALSE}
# de Bruin, G. P., & Henn, C. M. (2013). Dimensionality of the 9-item Utrecht Work Engagement Scale (UWES–9). Psychological Reports, 112(3), 788–799. https://doi.org/10.2466/01.03.PR0.112.3.788-799

# Partial bi-factor model from de Bruin & Henn (2013). 
# A general factor (WE) influences all items. 
# Two specific group factors (Vigor and Absorption) influence their respective items.
# The Dedication items' variance is fully explained by the general factor.
# The general factor is specified to be uncorrelated with the group factors.

partial.bifac.mod.deBruin <- "
    WE =~ UWES_1 + UWES_2 + UWES_3 + UWES_4 + UWES_5 + UWES_6 + UWES_7 + UWES_8 + UWES_9
    Vigor =~ UWES_1 + UWES_2 + UWES_5
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # Specify factors are orthogonal (uncorrelated)
    WE ~~ 0*Vigor
    WE ~~ 0*Absorption
    Vigor ~~ 0*Absorption
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
UWES.partial.bifac.deBruin <- sem(model = partial.bifac.mod.deBruin, data = data, std.lv = TRUE, ordered = TRUE)
partial.bifac.deBruin.sum <- summary(UWES.partial.bifac.deBruin, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterestimates(UWES.partial.bifac.deBruin, standardized = TRUE) # Will show standardized estimates and many other things
modificationindices(UWES.partial.bifac.deBruin, sort. = TRUE) # How can we improve our model
fitmeasures(UWES.partial.bifac.deBruin) # chisq.scaled - robust one

# DFI
DFI_partial_bifactor_deBruin <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = UWES.partial.bifac.deBruin,
  data = data
)

partial.bifac.deBruin.resid <- resid(UWES.partial.bifac.deBruin, "cor")
# Example of model comparison if needed, e.g., comparing to the three-factor model
# dif.test.partial.bifac.three.fac <- lavaan::anova(UWES.three.fac, UWES.partial.bifac.deBruin)
```

```{r CFA_three_factor_model_with_correlated_errors_Dominguez, include=FALSE}
# Domínguez-Salas, S., Rodríguez-Domínguez, C., Arcos-Romero, A. I., Allande-Cussó, R., García-Iglesias, J. J., & Gómez-Salgado, J. (2022). Psychometric Properties of the Utrecht Work Engagement Scale (UWES-9) in a Sample of Active Health Care Professionals in Spain. Psychology research and behavior management, 15, 3461–3472. https://doi.org/10.2147/PRBM.S387242

# Modified three-factor model with correlated errors from Domínguez-Salas et al. (2022).
# This is based on the standard three-factor model but adds correlations between the error terms of items 1 and 2, and items 8 and 9.
three.fac.mod.corr.errors.Dominguez <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5 
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # Correlated errors
    UWES_1 ~~ UWES_2
    UWES_8 ~~ UWES_9
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
UWES.three.fac.corr.errors.Dominguez <- sem(model = three.fac.mod.corr.errors.Dominguez, data = data, std.lv = TRUE, ordered = TRUE)
three.fac.mod.corr.errors.Dominguez.sum <- summary(UWES.three.fac.corr.errors.Dominguez, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterestimates(UWES.three.fac.corr.errors.Dominguez, standardized = TRUE) # Will show standardized estimates and many other things
modificationindices(UWES.three.fac.corr.errors.Dominguez, sort. = TRUE) # How can we improve our model
fitmeasures(UWES.three.fac.corr.errors.Dominguez) # chisq.scaled - robust one

# DFI
DFI_three_factor_corr_errors_Dominguez <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = UWES.three.fac.corr.errors.Dominguez,
  data = data
)

three.fac.mod.corr.errors.Dominguez.resid <- resid(UWES.three.fac.corr.errors.Dominguez, "cor")
# Example of model comparison if needed, e.g., comparing to the standard three-factor model
# dif.test.corr.errors.vs.standard.three.fac <- lavaan::anova(UWES.three.fac, UWES.three.fac.corr.errors.Dominguez)
```

```{r cfa_three_factor_corr_errors_balducci, include=FALSE}
# Balducci, C., Fraccaroli, F., & Schaufeli, W. B. (2010). Psychometric properties of the Italian version of the Utrecht Work Engagement Scale (UWES-9): A cross-cultural analysis. European Journal of Psychological Assessment, 26(2), 143–149. https://doi.org/10.1027/1015-5759/a000020

# Modified three-factor model from Balducci et al. (2010) with four correlated error terms.
three_fac_mod_corr_errors_balducci <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5 
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # Correlated errors specific to the Italian sample in the study
    UWES_1 ~~ UWES_2
    UWES_2 ~~ UWES_5
    UWES_6 ~~ UWES_8
    UWES_8 ~~ UWES_9
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
uwes_three_fac_corr_errors_balducci <- sem(model = three_fac_mod_corr_errors_balducci, data = data, std.lv = TRUE, ordered = TRUE)
three_fac_mod_corr_errors_balducci_sum <- summary(uwes_three_fac_corr_errors_balducci, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(uwes_three_fac_corr_errors_balducci, standardized = TRUE) 
modificationIndices(uwes_three_fac_corr_errors_balducci, sort. = TRUE)
fitMeasures(uwes_three_fac_corr_errors_balducci)

# DFI
dfi_three_factor_corr_errors_balducci <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = uwes_three_fac_corr_errors_balducci,
  data = data
)
```

```{r cfa_three_factor_corr_error_chaudhary, include=FALSE}
# Chaudhary, R., Rangnekar, S., & Barua, M. K. (2012). Psychometric evaluation of utrecht work engagement scale in an indian sample. Asia-Pacific Journal of Management Research and Innovation, 8(3), 343–350. https://doi.org/10.1177/2319510X1200800314

# Modified three-factor model with a correlated error term between the third Vigor item and the first Absorption item.
three_fac_mod_corr_error_chaudhary <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5 
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # Correlated error based on modification indices in the study
    UWES_5 ~~ UWES_6
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
uwes_three_fac_corr_error_chaudhary <- sem(model = three_fac_mod_corr_error_chaudhary, data = data, std.lv = TRUE, ordered = TRUE)
three_fac_mod_corr_error_chaudhary_sum <- summary(uwes_three_fac_corr_error_chaudhary, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(uwes_three_fac_corr_error_chaudhary, standardized = TRUE)
modificationIndices(uwes_three_fac_corr_error_chaudhary, sort. = TRUE)
fitMeasures(uwes_three_fac_corr_error_chaudhary)

# DFI
dfi_three_factor_corr_error_chaudhary <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = uwes_three_fac_corr_error_chaudhary,
  data = data
)
```

```{r cfa_two_factor_model_chaudhary, include=FALSE}
# Chaudhary, R., Rangnekar, S., & Barua, M. K. (2012). Psychometric evaluation of utrecht work engagement scale in an indian sample. Asia-Pacific Journal of Management Research and Innovation, 8(3), 343–350. https://doi.org/10.1177/2319510X1200800314

# Alternative two-factor model where Vigor and Absorption items load onto one factor.
two_fac_mod_chaudhary <- "
    VigAbs =~ UWES_1 + UWES_2 + UWES_5 + UWES_6 + UWES_8 + UWES_9
    Dedication =~ UWES_3 + UWES_4 + UWES_7
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
uwes_two_fac_chaudhary <- cfa(model = two_fac_mod_chaudhary, data = data, std.lv = TRUE, ordered = TRUE)
two_fac_mod_chaudhary_sum <- summary(uwes_two_fac_chaudhary, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(uwes_two_fac_chaudhary, standardized = TRUE)
modificationIndices(uwes_two_fac_chaudhary, sort. = TRUE)
fitMeasures(uwes_two_fac_chaudhary)

# DFI
dfi_two_factor_chaudhary <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = uwes_two_fac_chaudhary,
  data = data
)
```

```{r cfa_three_factor_corr_error_littman_ovadia, include=FALSE}
# Littman-Ovadia, H., & Balducci, C. (2013). Psychometric properties of the Hebrew version of the utrecht work engagement scale (UWES-9). European Journal of Psychological Assessment, 29(1), 58–63. https://doi.org/10.1027/1015-5759/a000121

# Modified three-factor model with a correlated error between the first two Vigor items.
three_fac_mod_corr_error_littman_ovadia <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5 
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # Correlated error
    UWES_1 ~~ UWES_2
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
uwes_three_fac_corr_error_littman_ovadia <- sem(model = three_fac_mod_corr_error_littman_ovadia, data = data, std.lv = TRUE, ordered = TRUE)
three_fac_mod_corr_error_littman_ovadia_sum <- summary(uwes_three_fac_corr_error_littman_ovadia, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(uwes_three_fac_corr_error_littman_ovadia, standardized = TRUE) 
modificationIndices(uwes_three_fac_corr_error_littman_ovadia, sort. = TRUE)
fitMeasures(uwes_three_fac_corr_error_littman_ovadia)

# DFI
dfi_three_factor_corr_error_littman_ovadia <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = uwes_three_fac_corr_error_littman_ovadia,
  data = data
)
```

```{r cfa_three_factor_mod_simbula_tran, include=FALSE}
# Simbula, S., Guglielmi, D., Schaufeli, W. B., & Depolo, M. (2013). An Italian validation of the Utrecht Work Engagement Scale: Characterization of engaged groups in a sample of schoolteachers. Bollettino di Psicologia Applicata, 268, 43-54.
# Tran, T. T. T., Watanabe, K., Imamura, K., et al. (2020). Reliability and validity of the Vietnamese version of the 9-item Utrecht Work Engagement Scale. Journal of Occupational Health, 62(1), e12157. https://doi.org/10.1002/1348-9585.12157

# Modified three-factor model with correlated errors.
three_fac_mod_simbula_tran <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5 
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # Correlated errors
    UWES_1 ~~ UWES_2
    UWES_8 ~~ UWES_9
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
uwes_three_fac_simbula_tran <- sem(model = three_fac_mod_simbula_tran, data = data, std.lv = TRUE, ordered = TRUE)
three_fac_simbula_tran_sum <- summary(uwes_three_fac_simbula_tran, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(uwes_three_fac_simbula_tran, standardized = TRUE) 
modificationIndices(uwes_three_fac_simbula_tran, sort. = TRUE)
fitMeasures(uwes_three_fac_simbula_tran)

# DFI
dfi_three_factor_simbula_tran <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = uwes_three_fac_simbula_tran,
  data = data
)
```

```{r cfa_three_factor_mod_seppala, include=FALSE}
# Seppälä, P., Mauno, S., Feldt, T., Hakanen, J., Kinnunen, U., Tolvanen, A., & Schaufeli, W. (2009). The construct validity of the Utrecht Work Engagement Scale: Multisample and longitudinal evidence. Journal of Happiness Studies, 10(4), 459–481. https://doi.org/10.1007/s10902-008-9100-y

# Modified three-factor model with a single correlated error.
three_fac_mod_seppala <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5 
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # Correlated error
    UWES_8 ~~ UWES_9
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
uwes_three_fac_seppala <- sem(model = three_fac_mod_seppala, data = data, std.lv = TRUE, ordered = TRUE)
three_fac_seppala_sum <- summary(uwes_three_fac_seppala, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(uwes_three_fac_seppala, standardized = TRUE) 
modificationIndices(uwes_three_fac_seppala, sort. = TRUE)
fitMeasures(uwes_three_fac_seppala)

# DFI
dfi_three_factor_seppala <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = uwes_three_fac_seppala,
  data = data
)
```

```{r cfa_three_factor_mod_zecca, include=FALSE}
# Zecca, G., Györkös, C., Becker, J., Massoudi, K., de Bruin, G. P., & Rossier, J. (2015). Validation of the French Utrecht Work Engagement Scale and its relationship with personality traits and impulsivity. Revue Européenne de Psychologie Appliquée/European Review of Applied Psychology, 65(1), 19-28. https://doi.org/10.1016/j.erap.2014.10.003

# Modified three-factor model with within-factor correlated errors.
three_fac_mod_zecca <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5 
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # Correlated errors
    UWES_1 ~~ UWES_2
    UWES_3 ~~ UWES_4
    UWES_8 ~~ UWES_9
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used. 
uwes_three_fac_zecca <- sem(model = three_fac_mod_zecca, data = data, std.lv = TRUE, ordered = TRUE)
three_fac_zecca_sum <- summary(uwes_three_fac_zecca, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(uwes_three_fac_zecca, standardized = TRUE)
modificationIndices(uwes_three_fac_zecca, sort. = TRUE)
fitMeasures(uwes_three_fac_zecca)

dfi_three_factor_zecca <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = uwes_three_fac_zecca,
  data = data
)
```

```{r cfa_two_factor_mod_panthee, include=FALSE}
# Panthee, B., Shimazu, A., & Kawakami, N. (2014). Validation of Nepalese version of Utrecht Work Engagement Scale. Journal of Occupational Health, 56(6), 421–429. https://doi.org/10.1539/joh.14-0041-OA

# Two-factor model (Dedication/Absorption and Vigor)
two_fac_mod_panthee <- "
    DedAbs =~ UWES_3 + UWES_4 + UWES_7 + UWES_6 + UWES_8 + UWES_9
    Vigor =~ UWES_1 + UWES_2 + UWES_5
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
uwes_two_fac_panthee <- cfa(model = two_fac_mod_panthee, data = data, std.lv = TRUE, ordered = TRUE)
two_fac_mod_panthee_sum <- summary(uwes_two_fac_panthee, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(uwes_two_fac_panthee, standardized = TRUE)
modificationIndices(uwes_two_fac_panthee, sort. = TRUE)
fitMeasures(uwes_two_fac_panthee)

# DFI
DFI_two_factor_panthee <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = uwes_two_fac_panthee,
  data = data
)

op_section <- prop_section(type = "continuous")
close_section <- prop_section(
    page_size = page_size(orient = "landscape", width = 17, height = 17), 
    type = "continuous")

```

```{r CFA_within_factor_corr_model, include=FALSE}
# This model synthesizes the modifications that demonstrated the best (though still imperfect) 
# performance in the DFI analyses. The goal is to address the multiple sources of local 
# misfit simultaneously to create a model that aligns with the DFI's "Level-0" (correctly specified) benchmarks.
# Theoretical justifications for correlated errors:
# - UWES_1 ~~ UWES_2: Both items refer to high energy levels ("bursting with energy," "strong and vigorous"). Their similar, active wording suggests shared variance beyond the general Vigor factor.
# - UWES_3 ~~ UWES_4: Both items refer to the inspirational aspect of the job ("enthusiastic about my job," "my job inspires me"). This shared focus on inspiration can create a correlation not captured by the broader Dedication factor.
# - UWES_8 ~~ UWES_9: Both items refer to the immersive experience of work ("immersed in my work," "get carried away when I'm working"). This captures a cognitive state of flow that might have shared variance beyond the general Absorption factor.

within_factor_corr_model <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5 
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # All plausible within-factor correlated errors
    UWES_1 ~~ UWES_2
    UWES_3 ~~ UWES_4
    UWES_8 ~~ UWES_9
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
UWES_within_factor_corr <- sem(model = within_factor_corr_model, data = data, std.lv = TRUE, ordered = TRUE)
within_factor_corr_sum <- summary(UWES_within_factor_corr, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(UWES_within_factor_corr, standardized = TRUE)
modificationIndices(UWES_within_factor_corr, sort. = TRUE)
fitMeasures(UWES_within_factor_corr)

# DFI for the within-factor correlated errors model
DFI_within_factor_corr <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = UWES_within_factor_corr,
  data = data
)
```

```{r CFA_replicated_errors_model, include=FALSE}
# This model tests the three-factor structure while accounting for the two most
# consistently replicated correlated errors in the international literature.
# This provides a strong test of a more parsimonious modified model.

replicated_errors_model <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5 
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    
    # Correlated errors replicated across multiple studies
    UWES_1 ~~ UWES_2
    UWES_8 ~~ UWES_9
"

# When "ordered" is set to "TRUE", the DWLS estimator is automatically used.
UWES_replicated_errors <- sem(model = replicated_errors_model, data = data, std.lv = TRUE, ordered = TRUE)
replicated_errors_sum <- summary(UWES_replicated_errors, rsquare = TRUE, standardized = TRUE, fit.measures = TRUE)
parameterEstimates(UWES_replicated_errors, standardized = TRUE)
modificationIndices(UWES_replicated_errors, sort. = TRUE)
fitMeasures(UWES_replicated_errors)

# DFI for the replicated errors model
DFI_replicated_errors <- cache_dynamic(
  cache_dir  = "./Supplementary_materials/Data_generated_during_code_running",
  model = UWES_replicated_errors,
  data = data
)

lavaan::anova(UWES_replicated_errors,UWES_within_factor_corr)
```

## Confirmatory Factor Analysis 

  Bartlett test ($\chi^2$ (`r bartlett.UWES$df`) = `r round(bartlett.UWES$chisq,digits=2)`, `r format_p(bartlett.UWES$p.value)`) as well as KMO (`r round(KMO(UWES.rep.poly)$MSA,digits = 2)`) revealed that UWES data are sufficiently correlated to perform factor analysis. Next, a series of CFAs were conducted to determine the optimal factorial structure of the UWES-9 for the Czech sample. Initial models based on standard one-factor, two-factor, hierarchical, and correlated three-factor structures demonstrated poor fit to the data. For instance, the standard three-factor model yielded an RMSEA of `r round(fitMeasures(UWES.three.fac)['rmsea.scaled'], 3)`, which was substantially higher than its dynamically-generated Level-0 cutoff of `r round(as.numeric(DFI_three_factor$cutoffs['Level-0', 'RMSEA']), 3)`, indicating a significant degree of misfit and the need for a more nuanced model.

This led to the testing of modified three-factor models to account for sources of local misfit. Two primary models were retained for a final, decisive comparison. The first, a Replicated Errors model, was specified based on the most consistent findings in the international literature. This model included correlated errors between items 1 and 2 (Vigor) and items 8 and 9 (Absorption), a modification independently identified across several validation studies (e.g., Domínguez-Salas et al., 2022; Simbula et al., 2013).

The second, a Three-Factor Model with Within-Factor Correlated Errors, included the same two correlations plus an additional error covariance between items 3 and 4 (Dedication). This more complex model was tested to confirm whether any remaining misfit in the "Replicated Errors" model could be systematically explained by this additional theoretically-grounded correlation (Zecca et al., 2015). The purpose of this test was to ensure that the most parsimonious model was selected only after confirming that a more complex—but still justifiable—model did not provide a statistically superior explanation of the data.

To adjudicate between these nested models, a scaled chi-square difference test was performed. The test revealed no significant improvement in fit for the more complex model with three correlated errors (*χ²*diff(`r lavaan::anova(UWES_replicated_errors, UWES_within_factor_corr, robust = TRUE)$'Df diff'[2]`) = `r format(round(lavaan::anova(UWES_replicated_errors, UWES_within_factor_corr, robust = TRUE)$'Chisq diff'[2], 2), nsmall = 2)`, *p* = `r format(round(lavaan::anova(UWES_replicated_errors, UWES_within_factor_corr, robust = TRUE)$'Pr(>Chisq)'[2], 2), nsmall = 2)`). Based on the principle of parsimony, the simpler "Replicated Errors" model was selected as the final and most appropriate model.

The fit of this final model was evaluated against dynamically generated fit index cutoffs. The model produced an excellent CFI (`r format(round(fitMeasures(UWES_replicated_errors)['cfi.scaled'], 3), nsmall = 3)`) and a low SRMR (`r format(round(fitMeasures(UWES_replicated_errors)['srmr'], 3), nsmall = 3)`). However, the RMSEA (`r format(round(fitMeasures(UWES_replicated_errors)['rmsea.scaled'], 3), nsmall = 3)`) was considerably higher than its dynamically generated Level-0 cutoff of `r format(round(as.numeric(DFI_replicated_errors$cutoffs['Level-0', 'RMSEA']), 3), nsmall = 3)`, indicating that while the model is superior to all tested alternatives, it still contains a non-trivial degree of misfit. This suggests that while this three-factor structure with modifications for item wording overlap is the best representation of the data, the UWES-9 scale may not perfectly capture the construct of work engagement within this sample. A summary of the fit indices for all tested models is provided in Table 2. Factor loadings ($\lambda$) in the Replicated Errors model were high (ranging from: `r round(min(select((filter(parameterestimates(UWES_replicated_errors,standardized = T), op %in% "=~")), std.all)), digits = 2)` to `r round(max(select((filter(parameterestimates(UWES_replicated_errors, standardized = T), op %in% "=~")), std.all)), digits = 2)`) as were correlations between the three factors (see Figure 1). Correlation between residuals in manifest variables was low: *r* =  range(`r round(min(resid(UWES_replicated_errors, "cor")$cov), digits = 2)` - `r round(max(resid(UWES_replicated_errors, "cor")$cov), digits = 2)`). Correlation matrix depicting relationships between item residuals can be found in the Supplementary Material x. 
  
(ref:my-figure-caption) SEM plot of the UWES Replicated Errors model with factor loadings and item residuals.

```{r my-figure, echo=FALSE, fig.cap="(ref:my-figure-caption)", message=FALSE, warning=FALSE}
semPaths(UWES_replicated_errors,layout = "tree2", whatLabels= "std",
         residuals = T, thresholds = F,        
         reorder = T, edge.label.cex= 1, fade=F, 
         intercepts = F, rotation = 1,
          # Formatting residuals
         curve=2,
         curvePivot = FALSE,
         filetype = c("eps"), filename = "Figure.1",
         nCharNodes = 20,style = "OpenMx", edge.label.position = 0.62,
         sizeLat = 9, sizeMan=8,edge.color="black")

knitr::include_graphics("Figure.1.eps") # this does not show image into word document however 

source("./R/sem_plot_all_models.R")
```
  
```{r}
block_section(op_section)
```

```{r FactorLoadings, echo=FALSE}
# # # 1. Grab the object names as characters
# names_dfi <- ls(pattern = "^DFI_|^dfi_")
# names_dfi
# 
# # 2. Build the argument list
# call_args <- list(
#   models           = names_dfi,
#   add_interpretation = FALSE,
#   show_fitted_model = TRUE,
#   add_separator_rows = FALSE,
#   remove_duplicated_model_names = FALSE,
#   bold_fitted_model = TRUE
# )
# 
# # 3. Call the function
# table_DFI <- do.call(create_dynamic_table, call_args)
# view(table_DFI)


# --- STEP 1: Define the lookup table (dictionary) for model names ---
# The names of the vector are the original, "ugly" R object names.
# The values are the pretty, publication-ready names.
publication_name_map <- c(
  "DFI_one_factor" = "1. One-Factor Model",
  "DFI_hierarch_factor" = "2. Hierarchical Model",
  "DFI_three_factor" = "3. Three-Factor Model (Standard)",
  "DFI_two_factor" = "4a. Two-Factor (Vigor-Dedication)",
  "dfi_two_factor_chaudhary" = "4b. Two-Factor (Vigor-Absorption)",
  "DFI_two_factor_panthee" = "4c. Two-Factor (Dedication-Absorption)",
  "dfi_three_factor_corr_errors_balducci" = "5a. Modified 3F (Balducci et al.)",
  "dfi_three_factor_corr_error_chaudhary" = "5b. Modified 3F (Chaudhary et al.)",
  "DFI_three_factor_corr_errors_Dominguez" = "5c. Modified 3F (Domínguez-Salas et al.)",
  "dfi_three_factor_corr_error_littman_ovadia" = "5d. Modified 3F (Littman-Ovadia & Balducci)",
  "dfi_three_factor_seppala" = "5e. Modified 3F (Seppälä et al.)",
  "dfi_three_factor_simbula_tran" = "5f. Modified 3F (Simbula et al./Tran et al.)",
  "dfi_three_factor_zecca" = "5g. Modified 3F (Zecca et al.)",
  "DFI_within_factor_corr" = "5h. Modified 3F (Within-Factor Errors)",
  "DFI_replicated_errors" = "6. Final Model (Replicated Errors)"
)

# --- STEP 2: Programmatically create new, cleanly named objects ---
# This loop creates copies of your DFI objects with valid R names based on the pretty names.
for (old_name in names(publication_name_map)) {
  pretty_name <- publication_name_map[[old_name]]
  
  # Create a valid R name from the pretty name (e.g., "1. One-Factor Model" -> "One_Factor_Model")
  valid_r_name <- gsub("[^A-Za-z0-9_]", "_", pretty_name) %>% # Replace non-alphanumeric with underscore
                  gsub("^\\d+[a-z]?\\.\\s*", "", .) # Remove leading numbers/letters like "1. " or "4a. "
  
  # Use assign() to create a new object with the valid name, copying the old object
  assign(valid_r_name, get(old_name, envir = .GlobalEnv))
}

# --- STEP 3: Create the character vector of the NEW, clean object names ---
new_dfi_object_names <- publication_name_map %>%
  unname() %>%
  sapply(function(pretty_name) {
    gsub("[^A-Za-z0-9_]", "_", pretty_name) %>%
    gsub("^\\d+[a-z]?\\.\\s*", "", .)
  })

# --- STEP 4: Generate the raw table using the NEW objects ---
raw_dfi_table <- create_dynamic_table(
  new_dfi_object_names,
  add_interpretation = FALSE,
  show_fitted_model = TRUE,
  add_separator_rows = FALSE,
  remove_duplicated_model_names = FALSE,
  bold_fitted_model = TRUE
)

# --- STEP 5: Perform a final, simple cleanup on the now-predictable names ---
DFI_table_publication_final <- raw_dfi_table %>%
  mutate(
    across(everything(), ~ str_replace_all(., "_", " ")), # Replace all underscores with spaces
    across(everything(), ~ str_remove(., "^Model "))     # Remove the "Model " prefix
  )

# --- STEP 6: Display the final, clean table ---
print(DFI_table_publication_final, n = Inf, width = Inf)

# Display the final, clean table
DFI_table_publication_final %>% apa_table()

```

```{r}
block_section(close_section)
```

## Item statistic and reliability
```{r internal_consistency_examination, message=FALSE, warning=FALSE, include=FALSE}
# UWES total
UWES.rel.tot=ufs::scaleStructure(select(ends_with(c("UWES_1", "UWES_2","UWES_3","UWES_4",
                                              "UWES_5", "UWES_6", "UWES_7", "UWES_8",
                                              "UWES_9")), .data = data), digits = 2, poly = TRUE, samples = 5000)
# UWES Vigor
UWES.rel.vig=ufs::scaleStructure(select(ends_with(c("UWES_1", "UWES_2", "UWES_5")), .data = data), digits = 2, poly = TRUE, samples = 5000)
# UWES Dedication 
UWES.rel.ded=ufs::scaleStructure(select(ends_with(c("UWES_3", "UWES_4", "UWES_7")), .data = data), digits = 2, poly = TRUE, samples = 5000)
# UWES Absorption
UWES.rel.abs=ufs::scaleStructure(select(ends_with(c("UWES_6", "UWES_8", "UWES_9")), .data = data), digits = 2, poly = TRUE, samples = 5000)
```

```{r item_statistic_table, message=FALSE, warning=FALSE, include=FALSE}
# there is need to drop NAs before calculation of polychoric correlations (i.e. for extraction of p-values to poly correlations) but in order to make results of previous code compatible, there is need to do this in the procedures above
data.no.na = data %>% 
  filter(!is.na(UWES))

# item statistic calculation
ITC.UWES=psych::alpha(x = select((starts_with(c("UWES_1", "UWES_2","UWES_3","UWES_4",
                                              "UWES_5", "UWES_6", "UWES_7", "UWES_8",
                                              "UWES_9"))),.data = data.no.na))
skew.kurt.UWES=describe(x = select(data.no.na, starts_with(c("UWES_1", "UWES_2","UWES_3","UWES_4",
                                              "UWES_5", "UWES_6", "UWES_7", "UWES_8",
                                              "UWES_9"))))

# calculating polychoric correlations 
UWES.cz.polych = polychoric(select((starts_with(c("UWES_1", "UWES_2","UWES_3","UWES_4",
                                              "UWES_5", "UWES_6", "UWES_7", "UWES_8",
                                              "UWES_9"))), .data = data.no.na), smooth = T) # polychoric correlation procedure
UWES.cz.polych$rho[upper.tri(UWES.cz.polych$rho)] <- NA # replacing the same values in matrix with na

# extract p values to poly correlations 
library(correlation)
library(gtools)
p.val.polych=cor_to_p(cor(select(starts_with(c("UWES_1", "UWES_2","UWES_3","UWES_4",
                                              "UWES_5", "UWES_6", "UWES_7", "UWES_8",
                                              "UWES_9")),.data = data.no.na)), n = nrow(data.no.na),method = "polychoric")$p

# p-values to stars
stars.to.cor = p.val.polych %>% stars.pval()
# two digits 
UWES.cz.polych$rho = UWES.cz.polych$rho %>% round(digits = 2) 
# paste p-values
poly.mat.star <- matrix(paste(UWES.cz.polych$rho, stars.to.cor, sep=""), ncol=ncol(p.val.polych)) 
# adding colnames to poly cor table
rownames(poly.mat.star) <- colnames(p.val.polych) 
# pasting colnames and rownames to cor table
colnames(poly.mat.star) <- paste(colnames(p.val.polych), "", sep="") 
# remove upper triangular and 1 diagonal
poly.mat.star[upper.tri(poly.mat.star, diag = FALSE)] <- "" 
# adding 1 on the diagonal
poly.mat.star[upper.tri(poly.mat.star, diag = FALSE)] <- "" 
# removing stars from 1 at the diagonal
diag(poly.mat.star)=str_replace_all(diag(poly.mat.star), "[:punct:]", replacement = "")

# selecting mean,
M=round(ITC.UWES$item.stats$mean,digits = 2)
# selecting SD
SD=round(ITC.UWES$item.stats$sd,digits = 2)
# selecting ITC item-total correlation
ITC=round(ITC.UWES$item.stats$r.cor,digits = 2)
# selecting skewness
Skewness=round(skew.kurt.UWES$skew,digits = 2)
# selecting kurtosis
kurtosis=round(skew.kurt.UWES$kurtosis, digits = 2)

# combine all
UWES.items.des=cbind(poly.mat.star,M,SD,ITC,Skewness,kurtosis) 
UWES.items.des = UWES.items.des %>% 
  as_tibble() %>% 
  mutate("M(SD)" = paste0("",M," (",SD,")")) %>% 
  select(!c("M","SD"))
```

  Internal consistency of the UWES total score was excellent: Cronbach's $\alpha$ = `r round(UWES.rel.tot$intermediate$alpha.ordinal.ci$est,digits=2)` 95% CI[`r round(UWES.rel.tot$intermediate$alpha.ordinal.ci$ci.lower,digits=2)` - `r round(UWES.rel.tot$intermediate$alpha.ordinal.ci$ci.upper,digits=2)`] and McDonald's $\omega_t$ = `r round(UWES.rel.tot$intermediate$omega.ordinal$est, digits=2 )` 95% CI[`r round(UWES.rel.tot$intermediate[["omega.ordinal.ci"]]$ci.lower, digits = 2)` - `r round(UWES.rel.tot$intermediate[["omega.ordinal.ci"]]$ci.upper, digits = 2)`]. When assessing the internal consistency of the UWES subcales, the highest values yielded Dedication subscale: Cronbach's $\alpha$ = `r round(UWES.rel.ded$intermediate$alpha.ordinal.ci$est,digits=2)` 95% CI[`r round(UWES.rel.ded$intermediate$alpha.ordinal.ci$ci.lower,digits=2)` - `r round(UWES.rel.ded$intermediate$alpha.ordinal.ci$ci.upper,digits=2)`] and McDonald's $\omega_t$ = `r round(UWES.rel.ded$intermediate$omega.ordinal$est, digits=2 )` 95% CI[`r round(UWES.rel.ded$intermediate[["omega.ordinal.ci"]]$ci.lower, digits = 2)` - `r round(UWES.rel.ded$intermediate[["omega.ordinal.ci"]]$ci.upper, digits = 2)`] followed by the Vigor subscale: Cronbach's $\alpha$ = `r round(UWES.rel.vig$intermediate$alpha.ordinal.ci$est,digits=2)` 95% CI[`r round(UWES.rel.vig$intermediate$alpha.ordinal.ci$ci.lower,digits=2)` - `r round(UWES.rel.vig$intermediate$alpha.ordinal.ci$ci.upper,digits=2)`] and McDonald's $\omega_t$ = `r round(UWES.rel.vig$intermediate$omega.ordinal$est, digits=2 )` 95% CI[`r round(UWES.rel.vig$intermediate[["omega.ordinal.ci"]]$ci.lower, digits = 2)` - `r round(UWES.rel.vig$intermediate[["omega.ordinal.ci"]]$ci.upper, digits = 2)`]. The lowest internal consistency was observed in the Absorption factor: Cronbach's $\alpha$ = `r round(UWES.rel.abs$intermediate$alpha.ordinal.ci$est,digits=2)` 95% CI[`r round(UWES.rel.abs$intermediate$alpha.ordinal.ci$ci.lower,digits=2)` - `r round(UWES.rel.abs$intermediate$alpha.ordinal.ci$ci.upper,digits=2)`] and McDonald's $\omega_t$ = `r round(UWES.rel.abs$intermediate$omega.ordinal$est, digits=2 )` 95% CI[`r round(UWES.rel.abs$intermediate[["omega.ordinal.ci"]]$ci.lower, digits = 2)` - `r round(UWES.rel.abs$intermediate[["omega.ordinal.ci"]]$ci.upper, digits = 2)`]. The Table 3 illustrates statistics of UWES items. In general, correlations between these items and item-total correlations were high. The lowest item-total correlation had item 9.    

```{r echo=FALSE}
# creating table 
UWES.items.des %>% 
  as_tibble(rownames = NA) %>% 
     mutate_all(~(replace(., is.na(.), ""))) %>% 
  as_huxtable(add_colnames = F) %>% 
  apa_table(
          caption = "Item statistic and Polychoric correlations between the UWES items", 
          note = "* p < 0.05; ** p < 0.01; *** p < 0.001, M = Mean, SD = Standard Deviation, ITC = Item-total correlation corrected for scale reliability and item overlap")
```

  Correlation analysis indicated that there is significant positive association between all UWES subscale and total score and extroversion. The highest correlation was found in the Vigor subscale. In addition, there was significant negative correlation between all UWES subscales and total score with neuroticism. The highest association was also found in the Vigor subscale. Moreover, the UWES total and its all subscales were associated with self-efficacy. The strongest association was observed in the Vigor subscale. Finally, there was no correlation between the UWES composite and subcale score with spirituality with exception of Dedication subscale (see Table 5).   

```{r correlation table, include=FALSE}
variab.cor.data=data[, c("UWES","UWES_V","UWES_D","UWES_A",
                         "BFI_E","BFI_N","Age","Gender","DSES","GSES")]
# recode variables to numeric
variab.cor.data = variab.cor.data %>% 
  mutate_all(as.numeric) 

iter.cor.teq.fin.data=corx::corx(variab.cor.data, method = "spearman", triangle = "lower", describe = c(M = mean, SD = sd), stars = c(0.05, 0.01, 0.001),note = "M = mean, SD = standard devation")

# create vector of rownames
row.nam.cor.tab=rownames(iter.cor.teq.fin.data$apa)

iter.cor.teq.fin.data$apa = iter.cor.teq.fin.data$apa %>% 
  as.data.frame() %>%   
  mutate("M(SD)" = paste0(M," (",SD,")")) %>% 
  select(!c("M","SD")) %>% 
  as.data.frame(row.names = row.nam.cor.tab)
  # rownames_to_column() %>% 
  # rename("-" = "rowname")
```

```{r echo=FALSE}
apa_table(iter.cor.teq.fin.data$apa, caption = "Correaltion matrix of the UWES, personality characteristics and socio-demographic indicators",
          note = "* p < 0.05; ** p < 0.01; *** p < 0.001; SD = standard deviation, M = mean, UWES = Utrecht Work Engagement Scale, BFI_N = Big Five Inventory - Neuroticism subscale, BFI_E = Big Five Inventory - Extraversion subscale, UWES_A = Utrecht Work Engagement Scale - Absorption subscale, UWES_D = Utrecht Work Engagement Scale - Dedication subscale, UWES_V = Utrecht Work Engagement Scale - Vigor subscale. DSES = Daily Spiritual Experience Scale, GSES = General Self Efficacy Scale") 
```

## Invariance testing and factor loadings 

```{r gender_invariance_UWES, include=FALSE}
# --- Step 1: Define the models with MANUAL scaling ---

# Model for the single-group (overall) baseline fit
# We still standardize the latent variance to 1 for interpretability
overall.model.UWES <- "
    Vigor =~ UWES_1 + UWES_2 + UWES_5
    Dedication =~ UWES_3 + UWES_4 + UWES_7
    Absorption =~ UWES_6 + UWES_8 + UWES_9
    # UWES_1 ~~ UWES_2
    # UWES_8 ~~ UWES_9
"
# --- Step 2: Run the single-group baseline model ---
baseline.cfa <- cfa(overall.model.UWES,
                    data = data,
                    ordered = TRUE,
                    # std.lv is now FALSE because we do it manually
                    estimator = "WLSMV",
                    meanstructure = TRUE)

# --- Step 3: Prepare data for multi-group analysis (Unchanged) ---
data.invar <- data %>%
  drop_na(UWES)

# --- Step 4: Manually conduct multi-group invariance testing ---
# We now use the MANUAL model and remove std.lv=TRUE from all calls

# Configural Invariance
fit.configural <- cfa(overall.model.UWES,
                      data = data.invar,
                      group = "Gender",
                      ordered = TRUE,
                      estimator = "WLSMV",
                      meanstructure = TRUE)

# Metric Invariance
fit.metric <- cfa(overall.model.UWES,
                  data = data.invar,
                  group = "Gender",
                  group.equal = "loadings",
                  ordered = TRUE,
                  estimator = "WLSMV",
                  meanstructure = TRUE)

# Scalar Invariance
fit.scalar <- cfa(overall.model.UWES,
                  data = data.invar,
                  group = "Gender",
                  group.equal = c("loadings", "intercepts"),
                  ordered = TRUE,
                  estimator = "WLSMV",
                  meanstructure = TRUE)

# Strict Invariance
fit.strict <- cfa(overall.model.UWES,
                  data = data.invar,
                  group = "Gender",
                  group.equal = c("loadings", "intercepts", "residuals"),
                  ordered = TRUE,
                  estimator = "WLSMV",
                  meanstructure = TRUE)


# --- Step 5: Build the fit table (This part should now work correctly) ---
fit.indices <- c('chisq.scaled', 'df.scaled', 'pvalue.scaled', 'cfi.scaled',
                 'tli.scaled', 'rmsea.scaled', "rmsea.ci.lower.scaled",
                 "rmsea.ci.upper.scaled", 'srmr')

tab.fit <- matrix(nrow = 5, ncol = 10)
colnames(tab.fit) <- c("Model", "x2", "df", "pvalue", "CFI", "TLI", "rmsea",
                       "rmsea.ci.lower", "rmsea.ci.upper", "SRMR")

# Populate the table
tab.fit[1,] <- c("Baseline", round(fitMeasures(baseline.cfa, fit.indices), 3))
tab.fit[2,] <- c("Configural", round(fitMeasures(fit.configural, fit.indices), 3))
tab.fit[3,] <- c("Metric", round(fitMeasures(fit.metric, fit.indices), 3))
tab.fit[4,] <- c("Scalar", round(fitMeasures(fit.scalar, fit.indices), 3))
tab.fit[5,] <- c("Strict", round(fitMeasures(fit.strict, fit.indices), 3))

tab.fit = tab.fit %>% 
  as_tibble() %>% 
  mutate(pvalue = as.numeric(pvalue)) %>% 
  mutate(pvalue = format_p(pvalue)) %>% 
  mutate(rmsea = paste0(rmsea," 90% CI (",rmsea.ci.lower,"-",rmsea.ci.upper,")")) %>% 
  select(!starts_with(c("rmsea.ci.","rmsea.ci.lower","rmsea.ci.upper")))
```

  Following the identification of the "Replicated Errors" model as the most plausible, albeit imperfect, structure in the single-group analysis, the next step was to test its measurement invariance across genders. However, attempts to apply the standard sequence of nested model constraints for invariance testing revealed fundamental model instability. A key diagnostic for a valid analysis is that the ($\chi^2$) statistic must increase or remain the same as a model becomes more constrained. Preliminary analyses using a simplified three-factor model produced an improper solution where the $\chi^2$ value illogically **decreased** upon applying metric constraints, a mathematical impossibility in a correctly specified model. This signaled that the underlying factor structure was too misspecified to be coherently tested for invariance.

To confirm this instability with the most robust specification, the final "Replicated Errors" model was used to establish a baseline **configural model** across genders. This definitive test confirmed the model's inadequacy, resulting in a very poor fit to the data ($\chi^2$(`r fitMeasures(fit.configural)['df.scaled']`) = `r round(fitMeasures(fit.configural)['chisq.scaled'], 2)`, `r format_p(fitMeasures(fit.configural)['pvalue.scaled'])`; CFI = `r format(round(fitMeasures(fit.configural)['cfi.scaled'], 3), nsmall = 3)`; RMSEA = `r format(round(fitMeasures(fit.configural)['rmsea.scaled'], 3), nsmall = 3)`). The severe misspecification indicated by these fit indices is the underlying cause of the instability observed throughout the analysis.

Because the model fails to produce a stable and well-fitting solution at the baseline configural level, the hierarchical process of invariance testing cannot proceed. The evidence of improper solutions and the extremely poor fit of the best-available model provide a clear conclusion: the three-factor structure of the UWES-9 is not invariant across genders in this sample. Consequently, valid comparisons of latent factor means for Vigor, Dedication, and Absorption between men and women are not justified.

  Results of the measurement equivalence indicated that across tested invariance models (configure, metric, scalar and strict) $\Delta$ of the CFI was < 0.01. This findings strongly suggest that the UWES assess working engagement equivalently in males and females (See Table 6).    

```{r echo=FALSE}
# creating table 
tab.fit %>% 
  as_tibble() %>% 
     mutate_all(~(replace(., is.na(.), ""))) %>% 
  as_huxtable(add_colnames = F) %>% 
  apa_table(col.names=c("Model","x2","df","p-value","CFI","TLI","RMSEA","SRMR"),
          caption = "Measurement eqivalence of the UWES between genders", 
          note = "x2 = chi-square, df = degrees of freedom, CFI = Comparative Fit Index, TLI = Tucker-Lewis index, RMSEA = Root Mean Square Error of Approximation, SRMR = Standardized Root Mean Square Residual, CI = confidence interval")

# rmarkdown::pandoc_convert("pokus.docx", output = "pokus.html")
# {r child = "pokus.html"}
```

```{r eval=FALSE, child= "pokus.md", include=FALSE}
```

## Association of the UWES with chronic health ilnesses 

```{r frist_regression, include=FALSE}
# Side-by-side Regression Models
# logistic regression model
# we have 34 analysis thus 0.05/34 = 0.001470588 = criterion P-value

data.reg = data %>% 
  mutate(across(starts_with("hlth_"), ~dplyr::recode_factor(.,
                                                     "0" = "no",
                                                     "1" = "yes"))) 
ra.b.1 <-
  glm(hlth_hypertension ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Hypertension")) %>%
  bold_p(t = 0.0007352941) 
ra.b.2 <-
  glm(hlth_hypertension ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Hypertension")) %>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.3 <-
  glm(hlth_diabetes ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Diabetes"))%>%
  bold_p(t = 0.0007352941) 
ra.b.4 <-
  glm(hlth_diabetes ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Diabetes"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.5 <-
  glm(hlth_arthritis ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Arthritis"))%>%
  bold_p(t = 0.0007352941) 
ra.b.6 <-
  glm(hlth_arthritis ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Arthritis"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.7 <-
  glm(hlth_astma ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Astma"))%>%
  bold_p(t = 0.0007352941) 
ra.b.8 <-
  glm(hlth_astma ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Astma"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.9 <-
  glm(hlth_psych_depress ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Depression/Anxiety"))%>%
  bold_p(t = 0.0007352941) 
ra.b.10 <-
  glm(hlth_psych_depress ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Depression/Anxiety"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.11 <-
  glm(hlth_ICHS ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Ischemic heart disease"))%>%
  bold_p(t = 0.0007352941) 
ra.b.12 <-
  glm(hlth_ICHS ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Ischemic heart disease"))%>%
  bold_p(t = 0.0007352941)
#_____________________________________________________________
ra.b.13 <-
  glm(hlth_obesity ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Obesity"))%>%
  bold_p(t = 0.0007352941) 
ra.b.14 <-
  glm(hlth_obesity ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Obesity"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.15 <-
  glm(hlth_stroke ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Stroke"))%>%
  bold_p(t = 0.0007352941) 
ra.b.16 <-
  glm(hlth_stroke ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Stroke"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________

ra.b.17 <-
  glm(hlth_back_pain ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Back pain"))%>%
  bold_p(t = 0.0007352941) 
ra.b.18 <-
  glm(hlth_back_pain ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Back pain"))%>%
  bold_p(t = 0.0007352941) 
#___________________________________________________________________________________________________________________
ra.b.19 <-
  glm(hlth_gastric_or_duodenal_ulcers ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Gastric or duodenal ulcers"))%>%
  bold_p(t = 0.0007352941) 
ra.b.20 <-
  glm(hlth_gastric_or_duodenal_ulcers ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Gastric or duodenal ulcers"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.21 <-
  glm(hlth_chronic_lung_disease ~ UWES + Age + Education + Gender, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Chronic lung disease"))%>%
  bold_p(t = 0.0007352941) 
ra.b.22 <-
  glm(hlth_chronic_lung_disease ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Chronic lung disease"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.23 <-
  glm(hlth_skin_diseases_eczema ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Skin diseases eczema"))%>%
  bold_p(t = 0.0007352941) 
ra.b.24 <-
  glm(hlth_skin_diseases_eczema ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Skin diseases eczema"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.25 <-
  glm(hlth_allergy ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Allergy"))%>%
  bold_p(t = 0.0007352941) 
ra.b.26 <-
  glm(hlth_allergy ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Allergy"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.27 <-
  glm(hlth_migraine ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Migraine"))%>%
  bold_p(t = 0.0007352941) 
ra.b.28 <-
  glm(hlth_migraine ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Migraine"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.29 <-
  glm(hlth_pain_of_unclear_origin ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Pain of unclear origin"))%>%
  bold_p(t = 0.0007352941) 
ra.b.30 <-
  glm(hlth_pain_of_unclear_origin ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Pain of unclear origin"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.31 <-
  glm(hlth_women_pain_in_small_etc ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Pain in the small pelvis"))%>%
  bold_p(t = 0.0007352941) 

ra.b.32 <-
  glm(hlth_women_pain_in_small_etc ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Pain in the small pelvis"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.33 <-
  glm(hlth_cancer ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Cancer"))%>%
  bold_p(t = 0.0007352941) 
ra.b.34 <-
  glm(hlth_cancer ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Cancer"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________
ra.b.35 <-
  glm(hlth_thyroid_disease ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Thyroid disease"))%>%
  bold_p(t = 0.0007352941) 
ra.b.36 <-
  glm(hlth_thyroid_disease ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Thyroid disease"))%>%
  bold_p(t = 0.0007352941) 
#_____________________________________________________________

ra.b.tab.pok1=tbl_stack(
  tbls = list(ra.b.1,
              ra.b.3,
              ra.b.5,
              ra.b.7,
              ra.b.9,
              ra.b.11,
              ra.b.13,
              ra.b.15,
              ra.b.17,
              ra.b.19,
              ra.b.21,
              ra.b.23,
              ra.b.25,
              ra.b.27,
              ra.b.29,
              ra.b.31,
              ra.b.33,
              ra.b.35)) %>% 
   modify_header(label = "**Table 2**") %>%  
     modify_footnote(ci ~ "CI = Confidence Interval, bold p value is corrected",
                     abbreviation = T) 
# printing merged table
ra.b.tab.pok2=tbl_stack(
  tbls = list(ra.b.2,
              ra.b.4,
              ra.b.6,
              ra.b.8,
              ra.b.10,
              ra.b.12,
              ra.b.14,
              ra.b.16,
              ra.b.18,
              ra.b.20,
              ra.b.22,
              ra.b.24,
              ra.b.26,
              ra.b.28,
              ra.b.30,
              ra.b.32,
              ra.b.34,
              ra.b.36)) %>% 
   modify_header(label = "**Table 2.1**") %>%  
     modify_footnote(ci ~ "CI = Confidence Interval, bold p value is corrected",
                     abbreviation = T) 

ra.b.t1=tbl_merge(
tbls = list(ra.b.tab.pok1,ra.b.tab.pok2),
tab_span = c("**ADJ(ra)**", "**NA(ra)**"))
```

```{r convert_gtsum_tab_into_tible, include=FALSE}
table.2=ra.b.t1

#show_header_names(table.2)
# if there is need to use this code in the some other research there is need to just replace the names of the columns (e.g. `95% CI_(RA)` by " `95% CI_(EMP)`) and delete or add the number of OR,p-val,CI columns

  # convert to tibble object
  table.2.tib= table.2 %>% as_tibble()
  
  # setting names
names.tab2=c("Table 2",
             "OR_(R)","95% CI_(R)","p-value_(R)", # the first names are crude and second for adjusted effect
             "OR_(Rna)","95% CI_(Rna)","p-value_(Rna)")

names(table.2.tib) <- names.tab2

  
   #ds=gtsummary::as_tibble(re.tab.1)
   table.2.tib.star = table.2.tib %>%
   dplyr::mutate(across(dplyr::contains("p-val"), ~str_replace_all(., '^>', ""))) %>%
   dplyr::mutate(TF_P=across(dplyr::contains("p-val"), ~str_detect(., pattern = "_"))) %>% 
   dplyr::mutate(across(dplyr::contains("p-val"), ~str_replace_all(., '__', ""))) %>% 
   dplyr::mutate(stars = across(dplyr::contains("p-val"), ~pander::add.significance.stars(., cutoffs = c(0.05, 0.01, 0.001))))
   table.2.tib.star = table.2.tib.star %>% 
   dplyr::mutate_at(dplyr::vars("OR_(R)"), ~paste0(., c(table.2.tib.star$stars$`p-value_(R)`))) %>%  # if more p value is present there is need add more rows here 
   dplyr::mutate_at(dplyr::vars("OR_(Rna)"), ~paste0(., c(table.2.tib.star$stars$`p-value_(Rna)`))) %>%  
   dplyr::mutate(across(dplyr::contains("OR"), ~str_replace_all(., " ", ""))) %>% 
   dplyr::mutate(across(dplyr::contains("OR"), ~str_replace_all(., "NA", " "))) %>% 
   dplyr::mutate(across(dplyr::contains("OR"), ~str_replace_all(., "^\\s+\\*+", " "))) %>% 
   dplyr::mutate(across(dplyr::contains("OR"), ~str_replace_all(., "^\\s+", NA_character_))) 
   # if command is not working there is need to remove in the last commant the ""sta"" column
  
      # creating the new column containing only: OR 95%CI(xx-xx)
    table.2.tib.star = table.2.tib.star %>% 
     mutate(cis1 = paste0('(',table.2.tib.star$`95% CI_(R)`,')'), 
            cis2 = paste0('(',table.2.tib.star$`95% CI_(Rna)`,')'))
    # replacing old columns
    table.2.tib.star = table.2.tib.star %>% 
      mutate(`OR_(R)`=paste(table.2.tib.star$`OR_(R)`, cis1, sep=" "),
             `OR_(Rna)`=paste(table.2.tib.star$`OR_(Rna)`, cis2, sep=" "))
    
    # deleting undesired symbols
    table.2.tib.star = table.2.tib.star %>% 
      select(dplyr::contains(c("Table","OR","TF"))) %>% 
      mutate(across(dplyr::contains("OR"), ~str_replace_all(., "NA", " "))) %>% 
      mutate(across(dplyr::contains("OR"), ~str_replace_all(., "^\\s+\\[ ]+", " "))) 
    # Adding prefix to corrected values
      # table.2.tib.star = table.2.tib.star %>% 
      # mutate(`OR_(R)` = case_when(table.2.tib.star$TF_P$`p-value_(R)` == "TRUE" ~ paste0("B", sep = "_", `OR_(R)`), 
      #                    TRUE ~ `OR_(R)`),
      #        `OR_(Rna)`= case_when(table.2.tib.star$TF_P$`p-value_(Rna)` == "TRUE" ~ paste0("B", sep = "_", `OR_(Rna)`), 
      #                    TRUE ~ `OR_(Rna)`),
      #         `OR_(RA)`= case_when(table.2.tib.star$TF_P$`p-value_(RA)` == "TRUE" ~ paste0("B", sep = "_",  `OR_(RA)`), 
      #                    TRUE ~ `OR_(RA)`),
      #         `OR_(RAna)` = case_when(table.2.tib.star$TF_P$`p-value_(RAna)` == "TRUE" ~ paste0("B", sep = "_", `OR_(RAna)`), 
      #                    TRUE ~  `OR_(RAna)`))
      
     # selecting only relevant columns
         table.2.tib.star = table.2.tib.star %>% 
          mutate(across(dplyr::contains("OR_"), ~str_replace_all(., "\\[+", " ["))) %>% 
            select(!dplyr::starts_with("TF_P")) %>% 
           tibble::add_row(.after = "Day structure") %>%  # there is need to add as much rows as is the number of rows in second part of the table 
          mutate("Crude effect" = "") %>%  
           mutate("Adjusted effect" = "") %>% 
          select(`Table 2`, "Crude effect", `OR_(Rna)`, "Adjusted effect", `OR_(R)`) %>%    # changing the position of crude effect 
             mutate_all( ~(na_if(., ""))) %>%
           janitor::remove_empty(which = c("cols")) %>% 
           rename("Crude effect" = `OR_(Rna)`,
                  "Adjusted effect" = `OR_(R)`)
         
      # transposing table 
         # convert to wider format
       tab.wide.1 = table.2.tib.star %>%
         t()
```

```{r preparation_to_print_tab, message=FALSE, warning=FALSE, include=FALSE}

# the only step here which is required here is to manually divide dataset into four parts and then rbind these togather 

# even a little bit wider
# tab.wide.1 %>% ncol()

tr.1=tab.wide.1[,c(12,15,1:3)] %>% as_tibble(rownames = NA)
tr.2=tab.wide.1[,c(5,14,17,18,4)] %>% as_tibble(rownames = NA)         
tr.3=tab.wide.1[,c(6:9,19)] %>% as_tibble(rownames = NA)
tr.4=tab.wide.1[,c(10,11,12,13,16)] %>% as_tibble(rownames = NA) 
         
         tab = bind_rows(tr.1,tr.2,tr.4,tr.3)
         tab = tab %>% 
           as_tibble(rownames = NA) %>% 
           rownames_to_column()  %>% 
           mutate(across(starts_with("rowname"), ~ str_replace_all(., "\\.+\\.+\\.+[[:digit:]]+", replacement = ""))) %>% 
           mutate(across(starts_with("rowname"), ~ str_replace_all(., "Table 2", replacement = ""))) %>% 
           mutate_all(~(replace(., is.na(.), ""))) %>%
           janitor::row_to_names(row_number = 1) 
         
# Behaviours
# dec.re.be.oas=glm(data$hlth_pain_of_unclear_origin   ~ UWES, data = data, family=binomial(logit))
# dec.re.be.oas=(exp(dec.re.be.oas$coefficients[-1])-1)*100  # percentage
```

Results of the regression analysis revealed that work engagement is significantly related with chronic diseases. Specifically, higher work engagement was significantly related with lower probability of developing skin diseases or eczema (in crude effect) pain of unclear origin (both crude and adjusted effect see Table 6). 

```{r echo=FALSE}
# creating table 
tab %>% 
  apa_table(
          caption = "Logistic regression table depicting associations (in odds ratios) between the UWES and chronic diseases", 
          note = "* p < 0.05; ** p < 0.01; *** p < 0.001, results are reported in odds ratios; Education and Work position were covariates in adjusted effect; values in brackets refers to 95% confidence interval for odds ratios")
```

# Association of the UWES with health risk behaviour 

```{r second_regression, include=FALSE}
# Side-by-side Regression Models
# logistic regression model
# we have 44 analysis thus 0.05/44 = 0.001136364 = criterion P-value

data.reg = data %>% 
  mutate(across(starts_with("unhealthy_behaviour_"), ~ifelse(. < 4, 0,
                                                                    1))) 

# "Less than once a week"
# "More than once a week"

ra.c.1 <-
  glm(unhealthy_behaviour_1 ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Smoked")) %>%
  bold_p(t = 0.001136364) 
ra.c.2 <-
  glm(unhealthy_behaviour_1 ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Smoked")) %>%
  bold_p(t = 0.001136364) 
#_____________________________________________________________
ra.c.3 <-
  glm(unhealthy_behaviour_2 ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Drunk alcohol"))%>%
  bold_p(t = 0.001136364) 
ra.c.4 <-
  glm(unhealthy_behaviour_2 ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Drunk alcohol"))%>%
  bold_p(t = 0.001136364) 
#_____________________________________________________________
ra.c.5 <-
  glm(unhealthy_behaviour_3 ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Used illegal drugs"))%>%
  bold_p(t = 0.001136364) 
ra.c.6 <-
  glm(unhealthy_behaviour_3 ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Used illegal drugs"))%>%
  bold_p(t = 0.001136364) 
#_____________________________________________________________
ra.c.7 <-
  glm(unhealthy_behaviour_4 ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Drunk coffee"))%>%
  bold_p(t = 0.001136364) 
ra.c.8 <-
  glm(unhealthy_behaviour_4 ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Drunk coffee"))%>%
  bold_p(t = 0.001136364) 
#_____________________________________________________________
ra.c.9 <-
  glm(unhealthy_behaviour_5 ~ UWES + Education + Work_position, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Used television or computer for recreation"))%>%
  bold_p(t = 0.001136364) 
ra.c.10 <-
  glm(unhealthy_behaviour_5 ~ UWES, family = binomial, data = data.reg) %>%
  tbl_regression(exponentiate = TRUE, include = "UWES", show_single_row = "UWES", 
                 label = list(UWES ~ "Used television or computer for recreation"))%>%
  bold_p(t = 0.001136364) 
#_____________________________________________________________

ra.c.tab.pok1=tbl_stack(
  tbls = list(ra.c.1,
              ra.c.3,
              ra.c.5,
              ra.c.7,
              ra.c.9)) %>% 
   modify_header(label = "**Table 2**") %>%  
     modify_footnote(ci ~ "CI = Confidence Interval, bold p value is corrected",
                     abbreviation = T) 
# printing merged table
ra.c.tab.pok2=tbl_stack(
  tbls = list(ra.c.2,
              ra.c.4,
              ra.c.6,
              ra.c.8,
              ra.c.10)) %>% 
   modify_header(label = "**Table 2.1**") %>%  
     modify_footnote(ci ~ "CI = Confidence Interval, bold p value is corrected",
                     abbreviation = T) 

ra.c.t1=tbl_merge(
tbls = list(ra.c.tab.pok1,ra.c.tab.pok2),
tab_span = c("**ADJ(ra)**", "**NA(ra)**"))
```

```{r convert_gtsum_tab_2_into_tible, include=FALSE}
table.3=ra.c.t1

#show_header_names(table.3)
# if there is need to use this code in the some other research there is need to just replace the names of the columns (e.g. `95% CI_(RA)` by " `95% CI_(EMP)`) and delete or add the number of OR,p-val,CI columns

  # convert to tibble object
  table.3.tib= table.3 %>% as_tibble()
  
  # setting names
names.tab2=c("Table 2",
             "OR_(R)","95% CI_(R)","p-value_(R)", # the first names are crude and second for adjusted effect
             "OR_(Rna)","95% CI_(Rna)","p-value_(Rna)")

names(table.3.tib) <- names.tab2 
# table.3 = expss::setnames(x = table.3.tib, new = names.tab2) # worked before but not now

  
   #ds=gtsummary::as_tibble(re.tab.1)
   table.3.tib.star = table.3.tib %>%
   dplyr::mutate(across(dplyr::contains("p-val"), ~str_replace_all(., '^>', ""))) %>%
   dplyr::mutate(TF_P=across(dplyr::contains("p-val"), ~str_detect(., pattern = "_"))) %>% 
   dplyr::mutate(across(dplyr::contains("p-val"), ~str_replace_all(., '__', ""))) %>% 
   dplyr::mutate(stars = across(dplyr::contains("p-val"), ~pander::add.significance.stars(., cutoffs = c(0.05, 0.01, 0.001))))
   table.3.tib.star = table.3.tib.star %>% 
   dplyr::mutate_at(dplyr::vars("OR_(R)"), ~paste0(., c(table.3.tib.star$stars$`p-value_(R)`))) %>%  # if more p value is present there is need add more rows here 
   dplyr::mutate_at(dplyr::vars("OR_(Rna)"), ~paste0(., c(table.3.tib.star$stars$`p-value_(Rna)`))) %>%  
   dplyr::mutate(across(dplyr::contains("OR"), ~str_replace_all(., " ", ""))) %>% 
   dplyr::mutate(across(dplyr::contains("OR"), ~str_replace_all(., "NA", " "))) %>% 
   dplyr::mutate(across(dplyr::contains("OR"), ~str_replace_all(., "^\\s+\\*+", " "))) %>% 
   dplyr::mutate(across(dplyr::contains("OR"), ~str_replace_all(., "^\\s+", NA_character_))) 
   # if command is not working there is need to remove in the last commant the ""sta"" column
  
      # creating the new column containing only: OR 95%CI(xx-xx)
    table.3.tib.star = table.3.tib.star %>% 
     mutate(cis1 = paste0('(',table.3.tib.star$`95% CI_(R)`,')'), 
            cis2 = paste0('(',table.3.tib.star$`95% CI_(Rna)`,')'))
    # replacing old columns
    table.3.tib.star = table.3.tib.star %>% 
      mutate(`OR_(R)`=paste(table.3.tib.star$`OR_(R)`, cis1, sep=" "),
             `OR_(Rna)`=paste(table.3.tib.star$`OR_(Rna)`, cis2, sep=" "))
    
    # deleting undesired symbols
    table.3.tib.star = table.3.tib.star %>% 
      select(dplyr::contains(c("Table","OR","TF"))) %>% 
      mutate(across(dplyr::contains("OR"), ~str_replace_all(., "NA", " "))) %>% 
      mutate(across(dplyr::contains("OR"), ~str_replace_all(., "^\\s+\\[ ]+", " "))) 
    # Adding prefix to corrected values
      # table.3.tib.star = table.3.tib.star %>% 
      # mutate(`OR_(R)` = case_when(table.3.tib.star$TF_P$`p-value_(R)` == "TRUE" ~ paste0("B", sep = "_", `OR_(R)`), 
      #                    TRUE ~ `OR_(R)`),
      #        `OR_(Rna)`= case_when(table.3.tib.star$TF_P$`p-value_(Rna)` == "TRUE" ~ paste0("B", sep = "_", `OR_(Rna)`), 
      #                    TRUE ~ `OR_(Rna)`),
      #         `OR_(RA)`= case_when(table.3.tib.star$TF_P$`p-value_(RA)` == "TRUE" ~ paste0("B", sep = "_",  `OR_(RA)`), 
      #                    TRUE ~ `OR_(RA)`),
      #         `OR_(RAna)` = case_when(table.3.tib.star$TF_P$`p-value_(RAna)` == "TRUE" ~ paste0("B", sep = "_", `OR_(RAna)`), 
      #                    TRUE ~  `OR_(RAna)`))
      
     # selecting only relevant columns
         table.3.tib.star = table.3.tib.star %>% 
          mutate(across(dplyr::contains("OR_"), ~str_replace_all(., "\\[+", " ["))) %>% 
            select(!dplyr::starts_with("TF_P")) %>% 
           tibble::add_row(.after = "Day structure") %>%  # there is need to add as much rows as is the number of rows in second part of the table 
          mutate("Crude effect" = "") %>%  
           mutate("Adjusted effect" = "") %>% 
          select(`Table 2`, "Crude effect", `OR_(Rna)`, "Adjusted effect", `OR_(R)`) %>%    # changing the position of crude effect 
             mutate_all( ~(na_if(., ""))) %>%
           janitor::remove_empty(which = c("cols")) %>% 
           rename("Crude effect" = `OR_(Rna)`,
                  "Adjusted effect" = `OR_(R)`)
         
      # transposing table 
         # convert to wider format
       tab.wide.2 = table.3.tib.star %>%
         t()
```

```{r preparation_to_print_tab_2, message=FALSE, warning=FALSE, include=FALSE}
# the only step here which is required here is to manually divide dataset into four parts and then rbind these togather 

# even a little bit wider
# tab.wide.2 %>% ncol()
         
         tab.wide.2 = tab.wide.2 %>% 
           as_tibble(rownames = NA) %>% 
           rownames_to_column()  %>% 
           mutate(across(starts_with("rowname"), ~ str_replace_all(., "\\.+\\.+\\.+[[:digit:]]+", replacement = ""))) %>% 
           mutate(across(starts_with("rowname"), ~ str_replace_all(., "Table 2", replacement = ""))) %>% 
           mutate_all(~(replace(., is.na(.), ""))) %>%
           janitor::row_to_names(row_number = 1) 
```

Results of logistic regression suggested that there is no relationship between work engagement and the smoking, alcohol drinking, drug abuse, coffee drinking or using computer or television for recreation in both crude and adjusted effect. Variable smoking was the most closer to the significance threshold. 

```{r echo=FALSE}
# creating table 
tab.wide.2 %>% 
  apa_table(
          caption = "Logistic regression table depicting associations (in odds ratios) between the UWES and health risk behaviours", 
          note = "* p < 0.05; ** p < 0.01; *** p < 0.001, results are reported in odds ratios; Education and Work position were covariates in adjusted effect; values in brackets refers to 95% confidence interval for odds ratios")
```

# Discussion

\newpage

---
appendix: "R/appendix.Rmd"
---

# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```


\newpage

# (APPENDIX) Appendix {-}

```{r}
op_section <- prop_section(type = "continuous")
close_section <- prop_section(
    page_size = page_size(orient = "landscape", width = 10, height = 10), 
    type = "continuous")
```

```{r}
block_section(op_section)
```

```{r child = "R/appendix.Rmd"}
```

```{r}
block_section(close_section)
```

